{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Post Earthquake Assesment of Buildings using Deep Learning.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "q2ItCZlSseKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4b35cdf8-0034-4d28-f516-8b617ba3f452"
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.2)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aOkQaLoushwu",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "e8e19dba-b2d2-4bc1-d6e6-e1dc2315fc66"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-50c09e73-45d4-41b2-8e57-19e6f3f51687\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-50c09e73-45d4-41b2-8e57-19e6f3f51687\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZCz99y3RszD9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H8Iw1ad2tMX9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2990
        },
        "outputId": "bf26bd7c-3db6-442d-f8d5-67c1e3d3462b"
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c buildnet"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Damaged_test_Beams.npy.zip to /content\n",
            "\r  0% 0.00/2.51M [00:00<?, ?B/s]\n",
            "100% 2.51M/2.51M [00:00<00:00, 84.1MB/s]\n",
            "Downloading yTest_UnDamaged_walls.npy to /content\n",
            "  0% 0.00/292 [00:00<?, ?B/s]\n",
            "100% 292/292 [00:00<00:00, 287kB/s]\n",
            "Downloading yTest_walls.npy to /content\n",
            "  0% 0.00/1.00k [00:00<?, ?B/s]\n",
            "100% 1.00k/1.00k [00:00<00:00, 888kB/s]\n",
            "Downloading yTrain_Beams.npy to /content\n",
            "  0% 0.00/1.18k [00:00<?, ?B/s]\n",
            "100% 1.18k/1.18k [00:00<00:00, 977kB/s]\n",
            "Downloading yTrain_buildings.npy to /content\n",
            "  0% 0.00/3.11k [00:00<?, ?B/s]\n",
            "100% 3.11k/3.11k [00:00<00:00, 2.83MB/s]\n",
            "Downloading yTrain_Columns.npy to /content\n",
            "  0% 0.00/2.70k [00:00<?, ?B/s]\n",
            "100% 2.70k/2.70k [00:00<00:00, 2.64MB/s]\n",
            "Downloading yTrain_Damaged_Beams.npy to /content\n",
            "  0% 0.00/476 [00:00<?, ?B/s]\n",
            "100% 476/476 [00:00<00:00, 392kB/s]\n",
            "Downloading yTrain_Damaged_columns.npy to /content\n",
            "  0% 0.00/2.29k [00:00<?, ?B/s]\n",
            "100% 2.29k/2.29k [00:00<00:00, 1.96MB/s]\n",
            "Downloading yTrain_Damaged_walls.npy to /content\n",
            "  0% 0.00/2.11k [00:00<?, ?B/s]\n",
            "100% 2.11k/2.11k [00:00<00:00, 2.05MB/s]\n",
            "Downloading yTrain_UnDamaged_Beams.npy to /content\n",
            "  0% 0.00/856 [00:00<?, ?B/s]\n",
            "100% 856/856 [00:00<00:00, 874kB/s]\n",
            "Downloading yTrain_UnDamaged_columns.npy to /content\n",
            "  0% 0.00/548 [00:00<?, ?B/s]\n",
            "100% 548/548 [00:00<00:00, 495kB/s]\n",
            "Downloading yTrain_UnDamaged_walls.npy to /content\n",
            "  0% 0.00/672 [00:00<?, ?B/s]\n",
            "100% 672/672 [00:00<00:00, 684kB/s]\n",
            "Downloading yTrain_walls.npy to /content\n",
            "  0% 0.00/2.64k [00:00<?, ?B/s]\n",
            "100% 2.64k/2.64k [00:00<00:00, 2.66MB/s]\n",
            "Downloading yTest_UnDamaged_columns.npy to /content\n",
            "  0% 0.00/244 [00:00<?, ?B/s]\n",
            "100% 244/244 [00:00<00:00, 209kB/s]\n",
            "Downloading Test_with_full_collapse.npy.zip to /content\n",
            "  0% 0.00/495k [00:00<?, ?B/s]\n",
            "100% 495k/495k [00:00<00:00, 146MB/s]\n",
            "Downloading Test_with_minor_collapse.npy.zip to /content\n",
            " 64% 5.00M/7.86M [00:00<00:00, 13.7MB/s]\n",
            "100% 7.86M/7.86M [00:00<00:00, 19.8MB/s]\n",
            "Downloading Test_with_no_collapse.npy.zip to /content\n",
            "  0% 0.00/2.66M [00:00<?, ?B/s]\n",
            "100% 2.66M/2.66M [00:00<00:00, 180MB/s]\n",
            "Downloading Train_with_full_collapse.npy.zip to /content\n",
            " 60% 5.00M/8.33M [00:00<00:00, 14.2MB/s]\n",
            "100% 8.33M/8.33M [00:00<00:00, 21.1MB/s]\n",
            "Downloading Train_with_major_collapse.npy.zip to /content\n",
            " 80% 26.0M/32.7M [00:00<00:00, 19.4MB/s]\n",
            "100% 32.7M/32.7M [00:00<00:00, 66.4MB/s]\n",
            "Downloading Train_with_minor_collapse.npy.zip to /content\n",
            " 81% 26.0M/32.3M [00:00<00:00, 17.8MB/s]\n",
            "100% 32.3M/32.3M [00:00<00:00, 59.9MB/s]\n",
            "Downloading Train_with_no_collapse.npy.zip to /content\n",
            " 84% 35.0M/41.8M [00:00<00:00, 19.9MB/s]\n",
            "100% 41.8M/41.8M [00:00<00:00, 50.6MB/s]\n",
            "Downloading y_train_with_no_collapse.npy to /content\n",
            "  0% 0.00/1.21k [00:00<?, ?B/s]\n",
            "100% 1.21k/1.21k [00:00<00:00, 1.27MB/s]\n",
            "Downloading yTest_with_full_collapse.npy to /content\n",
            "  0% 0.00/140 [00:00<?, ?B/s]\n",
            "100% 140/140 [00:00<00:00, 135kB/s]\n",
            "Downloading yTest_with_major_collapse.npy to /content\n",
            "  0% 0.00/288 [00:00<?, ?B/s]\n",
            "100% 288/288 [00:00<00:00, 243kB/s]\n",
            "Downloading yTest_with_minor_collapse.npy to /content\n",
            "  0% 0.00/336 [00:00<?, ?B/s]\n",
            "100% 336/336 [00:00<00:00, 289kB/s]\n",
            "Downloading yTest_with_no_collapse.npy to /content\n",
            "  0% 0.00/200 [00:00<?, ?B/s]\n",
            "100% 200/200 [00:00<00:00, 164kB/s]\n",
            "Downloading yTrain_with_full_collapse.npy to /content\n",
            "  0% 0.00/348 [00:00<?, ?B/s]\n",
            "100% 348/348 [00:00<00:00, 342kB/s]\n",
            "Downloading Test_with_major_collapse.npy.zip to /content\n",
            " 81% 5.00M/6.17M [00:00<00:00, 15.3MB/s]\n",
            "100% 6.17M/6.17M [00:00<00:00, 17.5MB/s]\n",
            "Downloading yTrain_with_major_collapse.npy to /content\n",
            "  0% 0.00/988 [00:00<?, ?B/s]\n",
            "100% 988/988 [00:00<00:00, 832kB/s]\n",
            "Downloading yTest_UnDamaged_Beams.npy to /content\n",
            "  0% 0.00/340 [00:00<?, ?B/s]\n",
            "100% 340/340 [00:00<00:00, 336kB/s]\n",
            "Downloading yTest_Damaged_columns.npy to /content\n",
            "  0% 0.00/1.05k [00:00<?, ?B/s]\n",
            "100% 1.05k/1.05k [00:00<00:00, 928kB/s]\n",
            "Downloading Damaged_test_Columns.npy.zip to /content\n",
            " 68% 23.0M/33.6M [00:00<00:00, 37.2MB/s]\n",
            "100% 33.6M/33.6M [00:00<00:00, 96.8MB/s]\n",
            "Downloading Damaged_test_walls.npy.zip to /content\n",
            " 24% 5.00M/21.0M [00:00<00:00, 34.8MB/s]\n",
            "100% 21.0M/21.0M [00:00<00:00, 83.4MB/s]\n",
            "Downloading Damaged_train_Beams.npy.zip to /content\n",
            " 46% 5.00M/11.0M [00:00<00:00, 31.1MB/s]\n",
            "100% 11.0M/11.0M [00:00<00:00, 53.7MB/s]\n",
            "Downloading Damaged_train_Columns.npy.zip to /content\n",
            " 92% 73.0M/79.0M [00:00<00:00, 69.7MB/s]\n",
            "100% 79.0M/79.0M [00:00<00:00, 89.5MB/s]\n",
            "Downloading Damaged_train_walls.npy.zip to /content\n",
            " 79% 48.0M/60.5M [00:00<00:00, 51.0MB/s]\n",
            "100% 60.5M/60.5M [00:00<00:00, 101MB/s] \n",
            "Downloading inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5.zip to /content\n",
            " 89% 69.0M/77.3M [00:00<00:00, 66.0MB/s]\n",
            "100% 77.3M/77.3M [00:00<00:00, 113MB/s] \n",
            "Downloading resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5.zip to /content\n",
            " 83% 69.0M/83.5M [00:00<00:00, 62.4MB/s]\n",
            "100% 83.5M/83.5M [00:00<00:00, 101MB/s] \n",
            "Downloading UnDamaged_test_Beams.npy.zip to /content\n",
            " 95% 5.00M/5.26M [00:00<00:00, 26.5MB/s]\n",
            "100% 5.26M/5.26M [00:00<00:00, 25.7MB/s]\n",
            "Downloading UnDamaged_test_Columns.npy.zip to /content\n",
            "  0% 0.00/3.42M [00:00<?, ?B/s]\n",
            "100% 3.42M/3.42M [00:00<00:00, 112MB/s]\n",
            "Downloading UnDamaged_test_walls.npy.zip to /content\n",
            "100% 4.08M/4.08M [00:00<00:00, 35.6MB/s]\n",
            "\n",
            "Downloading UnDamaged_train_Beams.npy.zip to /content\n",
            " 55% 9.00M/16.4M [00:00<00:00, 27.0MB/s]\n",
            "100% 16.4M/16.4M [00:00<00:00, 41.5MB/s]\n",
            "Downloading UnDamaged_train_Columns.npy.zip to /content\n",
            " 37% 5.00M/13.5M [00:00<00:00, 30.2MB/s]\n",
            "100% 13.5M/13.5M [00:00<00:00, 53.8MB/s]\n",
            "Downloading yTest_Damaged_walls.npy to /content\n",
            "  0% 0.00/864 [00:00<?, ?B/s]\n",
            "100% 864/864 [00:00<00:00, 844kB/s]\n",
            "Downloading UnDamaged_train_walls.npy.zip to /content\n",
            " 38% 5.00M/13.1M [00:00<00:00, 14.1MB/s]\n",
            "100% 13.1M/13.1M [00:00<00:00, 33.2MB/s]\n",
            "Downloading Xtest_Beams.npy.zip to /content\n",
            " 64% 5.00M/7.78M [00:00<00:00, 30.7MB/s]\n",
            "100% 7.78M/7.78M [00:00<00:00, 37.0MB/s]\n",
            "Downloading XTest_buildings.npy.zip to /content\n",
            " 29% 5.00M/17.2M [00:00<00:00, 26.3MB/s]\n",
            "100% 17.2M/17.2M [00:00<00:00, 68.1MB/s]\n",
            "Downloading Xtest_Columns.npy.zip to /content\n",
            " 92% 34.0M/37.1M [00:00<00:00, 35.8MB/s]\n",
            "100% 37.1M/37.1M [00:00<00:00, 68.8MB/s]\n",
            "Downloading XTest_walls.npy.zip to /content\n",
            " 20% 5.00M/25.1M [00:00<00:01, 21.0MB/s]\n",
            "100% 25.1M/25.1M [00:00<00:00, 72.0MB/s]\n",
            "Downloading Xtrain_Beams.npy.zip to /content\n",
            " 33% 9.00M/27.4M [00:00<00:00, 24.6MB/s]\n",
            "100% 27.4M/27.4M [00:00<00:00, 55.8MB/s]\n",
            "Downloading XTrain_buildings.npy.zip to /content\n",
            " 91% 105M/115M [00:01<00:00, 70.8MB/s] \n",
            "100% 115M/115M [00:01<00:00, 95.2MB/s]\n",
            "Downloading Xtrain_Columns.npy.zip to /content\n",
            " 97% 90.0M/92.5M [00:00<00:00, 63.2MB/s]\n",
            "100% 92.5M/92.5M [00:00<00:00, 112MB/s] \n",
            "Downloading XTrain_walls.npy.zip to /content\n",
            " 98% 72.0M/73.6M [00:00<00:00, 55.1MB/s]\n",
            "100% 73.6M/73.6M [00:01<00:00, 76.0MB/s]\n",
            "Downloading yTest_Beams.npy to /content\n",
            "  0% 0.00/420 [00:00<?, ?B/s]\n",
            "100% 420/420 [00:00<00:00, 420kB/s]\n",
            "Downloading yTest_buildings.npy to /content\n",
            "  0% 0.00/580 [00:00<?, ?B/s]\n",
            "100% 580/580 [00:00<00:00, 581kB/s]\n",
            "Downloading yTest_Columns.npy to /content\n",
            "  0% 0.00/1.17k [00:00<?, ?B/s]\n",
            "100% 1.17k/1.17k [00:00<00:00, 1.03MB/s]\n",
            "Downloading yTest_Damaged_Beams.npy to /content\n",
            "  0% 0.00/208 [00:00<?, ?B/s]\n",
            "100% 208/208 [00:00<00:00, 170kB/s]\n",
            "Downloading vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5.zip to /content\n",
            " 79% 41.0M/52.2M [00:00<00:00, 47.5MB/s]\n",
            "100% 52.2M/52.2M [00:00<00:00, 106MB/s] \n",
            "Downloading yTrain_with_minor_collapse.npy to /content\n",
            "  0% 0.00/992 [00:00<?, ?B/s]\n",
            "100% 992/992 [00:00<00:00, 860kB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VSEoEgYLtPjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1529
        },
        "outputId": "13ebbd48-cfe7-4ba3-c0aa-c74785ab4b40"
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!unzip Train_with_no_collapse.npy.zip\n",
        "!unzip Train_with_major_collapse.npy.zip\n",
        "!unzip Train_with_minor_collapse.npy.zip\n",
        "!unzip Train_with_full_collapse.npy.zip\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "y_train1 = np.load('y_train_with_no_collapse.npy')\n",
        "y_train2 = np.load('yTrain_with_minor_collapse.npy')\n",
        "y_train3 = np.load('yTrain_with_major_collapse.npy')\n",
        "y_train4 = np.load('yTrain_with_full_collapse.npy')\n",
        "print(y_train1.shape)\n",
        "print(y_train2.shape)\n",
        "print(y_train3.shape)\n",
        "print(y_train4.shape)\n",
        "\n",
        "\n",
        "y_val1 = np.load('yTest_with_no_collapse.npy')\n",
        "y_val2 = np.load('yTest_with_minor_collapse.npy')\n",
        "y_val3 = np.load('yTest_with_major_collapse.npy')\n",
        "y_val4 = np.load('yTest_with_full_collapse.npy')\n",
        "for i in range(len(y_val4)):\n",
        "  y_val4[i] = 4\n",
        "def y_out(y, num_classes = 4):\n",
        "  y1 = np.zeros((y.shape[0],num_classes))\n",
        "  for i in range(len(y)):\n",
        "    y1[i,y[i]-1] = 1\n",
        "  \n",
        "  return y1\n",
        "y_val1 = y_out(y_val1)\n",
        "y_val2 = y_out(y_val2)\n",
        "y_val3 = y_out(y_val3)\n",
        "y_val4 = y_out(y_val4)\n",
        "print(y_val1.shape)\n",
        "print(y_val2.shape)\n",
        "print(y_val3.shape)\n",
        "print(y_val4.shape)\n",
        "print(\"  \")\n",
        "y_val = np.concatenate((y_val1, y_val2, y_val3, y_val4), axis = 0)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Damaged_test_Beams.npy.zip\n",
            " Damaged_test_Columns.npy.zip\n",
            " Damaged_test_walls.npy.zip\n",
            " Damaged_train_Beams.npy.zip\n",
            " Damaged_train_Columns.npy.zip\n",
            " Damaged_train_walls.npy.zip\n",
            " inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\n",
            "'kaggle (1).json'\n",
            " kaggle.json\n",
            " resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            " resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\n",
            " sample_data\n",
            " Test_with_full_collapse.npy\n",
            " Test_with_full_collapse.npy.zip\n",
            " Test_with_major_collapse.npy\n",
            " Test_with_major_collapse.npy.zip\n",
            " Test_with_minor_collapse.npy\n",
            " Test_with_minor_collapse.npy.zip\n",
            " Test_with_no_collapse.npy\n",
            " Test_with_no_collapse.npy.zip\n",
            " Train_with_full_collapse.npy\n",
            " Train_with_full_collapse.npy.zip\n",
            " Train_with_major_collapse.npy\n",
            " Train_with_major_collapse.npy.zip\n",
            " Train_with_minor_collapse.npy\n",
            " Train_with_minor_collapse.npy.zip\n",
            " Train_with_no_collapse.npy\n",
            " Train_with_no_collapse.npy.zip\n",
            " UnDamaged_test_Beams.npy.zip\n",
            " UnDamaged_test_Columns.npy.zip\n",
            " UnDamaged_test_walls.npy.zip\n",
            " UnDamaged_train_Beams.npy.zip\n",
            " UnDamaged_train_Columns.npy.zip\n",
            " UnDamaged_train_walls.npy.zip\n",
            " VGG16-transferlearning.model\n",
            " vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\n",
            " Xtest_Beams.npy.zip\n",
            " XTest_buildings.npy.zip\n",
            " Xtest_Columns.npy.zip\n",
            " XTest_walls.npy.zip\n",
            " Xtrain_Beams.npy.zip\n",
            " XTrain_buildings.npy.zip\n",
            " Xtrain_Columns.npy.zip\n",
            " XTrain_walls.npy.zip\n",
            " yTest_Beams.npy\n",
            " yTest_buildings.npy\n",
            " yTest_Columns.npy\n",
            " yTest_Damaged_Beams.npy\n",
            " yTest_Damaged_columns.npy\n",
            " yTest_Damaged_walls.npy\n",
            " yTest_UnDamaged_Beams.npy\n",
            " yTest_UnDamaged_columns.npy\n",
            " yTest_UnDamaged_walls.npy\n",
            " yTest_walls.npy\n",
            " yTest_with_full_collapse.npy\n",
            " yTest_with_major_collapse.npy\n",
            " yTest_with_minor_collapse.npy\n",
            " yTest_with_no_collapse.npy\n",
            " yTrain_Beams.npy\n",
            " yTrain_buildings.npy\n",
            " yTrain_Columns.npy\n",
            " yTrain_Damaged_Beams.npy\n",
            " yTrain_Damaged_columns.npy\n",
            " yTrain_Damaged_walls.npy\n",
            " yTrain_UnDamaged_Beams.npy\n",
            " yTrain_UnDamaged_columns.npy\n",
            " yTrain_UnDamaged_walls.npy\n",
            " yTrain_walls.npy\n",
            " yTrain_with_full_collapse.npy\n",
            " yTrain_with_major_collapse.npy\n",
            " yTrain_with_minor_collapse.npy\n",
            " y_train_with_no_collapse.npy\n",
            "Archive:  Train_with_no_collapse.npy.zip\n",
            "replace Train_with_no_collapse.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Archive:  Train_with_major_collapse.npy.zip\n",
            "replace Train_with_major_collapse.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Archive:  Train_with_minor_collapse.npy.zip\n",
            "replace Train_with_minor_collapse.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Archive:  Train_with_full_collapse.npy.zip\n",
            "replace Train_with_full_collapse.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "(279,)\n",
            "(216,)\n",
            "(215,)\n",
            "(55,)\n",
            "(18, 4)\n",
            "(52, 4)\n",
            "(40, 4)\n",
            "(3, 4)\n",
            "  \n",
            "(113, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x3Fxs-FTzi_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "290d270f-104a-457a-de6d-24d67dde0c67"
      },
      "cell_type": "code",
      "source": [
        "def y_out(y, num_classes = 4):\n",
        "  y1 = np.zeros((y.shape[0],num_classes))\n",
        "  for i in range(len(y)):\n",
        "    y1[i,y[i]-1] = 1\n",
        "  \n",
        "  return y1\n",
        "\n",
        "y_train1 = y_out(y_train1)\n",
        "y_train2 = y_out(y_train2)\n",
        "y_train3 = y_out(y_train3)\n",
        "y_train4 = y_out(y_train4)\n",
        "\n",
        "\n",
        "\n",
        "print(y_train1.shape)\n",
        "print(y_train2.shape)\n",
        "print(y_train3.shape)\n",
        "print(y_train4.shape)\n",
        "\n",
        "y_train = np.concatenate((y_train1, y_train2, y_train3, y_train4), axis = 0)\n",
        "print(y_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "!unzip Test_with_no_collapse.npy.zip\n",
        "!unzip Test_with_minor_collapse.npy.zip   \n",
        "!unzip Test_with_major_collapse.npy.zip\n",
        "!unzip Test_with_full_collapse.npy.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(279, 4)\n",
            "(216, 4)\n",
            "(215, 4)\n",
            "(55, 4)\n",
            "(765, 4)\n",
            "Archive:  Test_with_no_collapse.npy.zip\n",
            "replace Test_with_no_collapse.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Archive:  Test_with_minor_collapse.npy.zip\n",
            "replace Test_with_minor_collapse.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Archive:  Test_with_major_collapse.npy.zip\n",
            "replace Test_with_major_collapse.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Archive:  Test_with_full_collapse.npy.zip\n",
            "replace Test_with_full_collapse.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ipELQpv1sIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8299
        },
        "outputId": "68741d7d-70c4-4b6e-d3cd-7a7666657323"
      },
      "cell_type": "code",
      "source": [
        "print(y_train1)\n",
        "print(y_train2)\n",
        "print(y_train3)\n",
        "print(y_train4)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n",
            "[[0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]]\n",
            "[[0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]]\n",
            "[[0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2S9K5oTuznLF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6665f8a3-c996-4aa6-b475-91d5a13f962e"
      },
      "cell_type": "code",
      "source": [
        "X_val1 = np.load('Test_with_no_collapse.npy')\n",
        "X_val2 = np.load('Test_with_minor_collapse.npy')\n",
        "X_val3 = np.load('Test_with_major_collapse.npy')\n",
        "X_val4 = np.load('Test_with_full_collapse.npy')\n",
        "\n",
        "print(X_val1.shape)\n",
        "print(X_val2.shape)\n",
        "print(X_val3.shape)\n",
        "print(X_val4.shape)\n",
        "\n",
        "\n",
        "X_val = np.concatenate((X_val1,X_val2,X_val3,X_val4), axis = 0)\n",
        "print(X_val.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18, 224, 224, 3)\n",
            "(52, 224, 224, 3)\n",
            "(40, 224, 224, 3)\n",
            "(3, 224, 224, 3)\n",
            "(113, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YraiSyilz9md",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6488
        },
        "outputId": "50b633b3-4356-466b-e6cd-a68efcdf26b1"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X_train1 = np.load('Train_with_no_collapse.npy')\n",
        "X_train2 = np.load('Train_with_minor_collapse.npy')\n",
        "X_train3 = np.load('Train_with_major_collapse.npy')\n",
        "X_train4 = np.load('Train_with_full_collapse.npy')\n",
        "X_train = np.concatenate((X_train1, X_train2, X_train3, X_train4), axis = 0)\n",
        "print(X_train1.shape)\n",
        "print(X_train2.shape)\n",
        "print(X_train3.shape)\n",
        "print(X_train4.shape)\n",
        "print(X_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Flatten, Activation, Dropout\n",
        "from keras import applications\n",
        "from keras.applications import VGG16, InceptionV3, ResNet50\n",
        "\n",
        "image_size = 224\n",
        "\n",
        "vgg_conv = ResNet50(weights = 'imagenet', include_top = False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "vgg_conv.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(279, 224, 224, 3)\n",
            "(216, 224, 224, 3)\n",
            "(215, 224, 224, 3)\n",
            "(55, 224, 224, 3)\n",
            "(765, 224, 224, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8d3mhNQK0SAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6350
        },
        "outputId": "0bdf93bf-a718-4829-81ba-050ec65ad477"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Flatten, Activation, Dropout\n",
        "from keras import applications\n",
        "from keras.applications import VGG16, InceptionV3, ResNet50\n",
        "\n",
        "image_size = 224\n",
        "\n",
        "vgg_conv = ResNet50(weights = 'imagenet', include_top = False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "vgg_conv.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 4s 0us/step\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4EeJHU7-0JNE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5add14e8-cfe4-4f16-9f56-42375907e76c"
      },
      "cell_type": "code",
      "source": [
        "!unzip resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5.zip"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5.zip\n",
            "  inflating: resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rRridd230sV8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights_path = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyuy1ttR0vtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6485
        },
        "outputId": "aed3a4af-b8e7-423d-de61-e470280d4821"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model, load_model\n",
        "\n",
        "vgg_conv.load_weights(weights_path)\n",
        "\n",
        "x = Flatten()(vgg_conv.get_layer('activation_49').output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs = vgg_conv.input, outputs = x)\n",
        "model.compile(loss='categorical_crossentropy', optimizer = optimizers.Adam(lr=0.00006, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 100352)       0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 512)          51380736    flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 512)          0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 256)          131328      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 256)          0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 4)            1028        dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 75,100,804\n",
            "Trainable params: 75,047,684\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Qyy98m41Hjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2705
        },
        "outputId": "4b205716-412f-4cf9-d8f0-16681e05e76a"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "batch_size = 50\n",
        "epochs = 80\n",
        "\n",
        "train_datagen = ImageDataGenerator(rotation_range = 10, width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip=True)\n",
        "\n",
        "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size = batch_size),\n",
        "                             steps_per_epoch = X_train.shape[0] // batch_size,\n",
        "                             epochs = epochs,\n",
        "                             validation_data = (X_val, y_val),\n",
        "                             callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "15/15 [==============================] - 41s 3s/step - loss: 2.8407 - acc: 0.3720 - val_loss: 0.8437 - val_acc: 0.5929\n",
            "Epoch 2/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 1.6051 - acc: 0.5238 - val_loss: 0.7035 - val_acc: 0.7257\n",
            "Epoch 3/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 1.1675 - acc: 0.6107 - val_loss: 0.6076 - val_acc: 0.7522\n",
            "Epoch 4/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 1.0190 - acc: 0.6486 - val_loss: 0.5689 - val_acc: 0.7876\n",
            "Epoch 5/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.9407 - acc: 0.6584 - val_loss: 0.4831 - val_acc: 0.8142\n",
            "Epoch 6/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.7198 - acc: 0.7182 - val_loss: 0.4697 - val_acc: 0.8230\n",
            "Epoch 7/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.7401 - acc: 0.7224 - val_loss: 0.3890 - val_acc: 0.8407\n",
            "Epoch 8/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.7758 - acc: 0.7139 - val_loss: 0.5445 - val_acc: 0.7965\n",
            "Epoch 9/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.6191 - acc: 0.7813 - val_loss: 0.4364 - val_acc: 0.8319\n",
            "Epoch 10/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.4965 - acc: 0.8243 - val_loss: 0.4173 - val_acc: 0.8319\n",
            "Epoch 11/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.5080 - acc: 0.8190 - val_loss: 0.4036 - val_acc: 0.8584\n",
            "Epoch 12/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.3859 - acc: 0.8468 - val_loss: 0.4271 - val_acc: 0.8584\n",
            "Epoch 13/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.3966 - acc: 0.8455 - val_loss: 0.4511 - val_acc: 0.8407\n",
            "Epoch 14/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.3636 - acc: 0.8695 - val_loss: 0.5835 - val_acc: 0.8053\n",
            "Epoch 15/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.3449 - acc: 0.8925 - val_loss: 0.4939 - val_acc: 0.8673\n",
            "Epoch 16/80\n",
            "15/15 [==============================] - 21s 1s/step - loss: 0.3156 - acc: 0.8791 - val_loss: 0.5748 - val_acc: 0.8407\n",
            "Epoch 17/80\n",
            "15/15 [==============================] - 21s 1s/step - loss: 0.2632 - acc: 0.9080 - val_loss: 0.7011 - val_acc: 0.8319\n",
            "Epoch 18/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.2493 - acc: 0.9168 - val_loss: 0.5841 - val_acc: 0.8319\n",
            "Epoch 19/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.2562 - acc: 0.8992 - val_loss: 0.6269 - val_acc: 0.8407\n",
            "Epoch 20/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.2548 - acc: 0.9097 - val_loss: 0.6604 - val_acc: 0.8230\n",
            "Epoch 21/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1933 - acc: 0.9369 - val_loss: 0.4380 - val_acc: 0.8673\n",
            "Epoch 22/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.2154 - acc: 0.9358 - val_loss: 0.5789 - val_acc: 0.8319\n",
            "Epoch 23/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1567 - acc: 0.9438 - val_loss: 0.5239 - val_acc: 0.8673\n",
            "Epoch 24/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1910 - acc: 0.9367 - val_loss: 0.6413 - val_acc: 0.8496\n",
            "Epoch 25/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1934 - acc: 0.9382 - val_loss: 0.9491 - val_acc: 0.7876\n",
            "Epoch 26/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1613 - acc: 0.9527 - val_loss: 0.5297 - val_acc: 0.8407\n",
            "Epoch 27/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1294 - acc: 0.9391 - val_loss: 0.6772 - val_acc: 0.8584\n",
            "Epoch 28/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1040 - acc: 0.9639 - val_loss: 0.6925 - val_acc: 0.8761\n",
            "Epoch 29/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1082 - acc: 0.9636 - val_loss: 0.6079 - val_acc: 0.8584\n",
            "Epoch 30/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0992 - acc: 0.9570 - val_loss: 0.5619 - val_acc: 0.8850\n",
            "Epoch 31/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1137 - acc: 0.9650 - val_loss: 0.6527 - val_acc: 0.8496\n",
            "Epoch 32/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1283 - acc: 0.9516 - val_loss: 0.7224 - val_acc: 0.8319\n",
            "Epoch 33/80\n",
            "15/15 [==============================] - 21s 1s/step - loss: 0.1163 - acc: 0.9693 - val_loss: 0.7928 - val_acc: 0.7965\n",
            "Epoch 34/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1046 - acc: 0.9639 - val_loss: 0.5654 - val_acc: 0.8673\n",
            "Epoch 35/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1391 - acc: 0.9527 - val_loss: 0.7521 - val_acc: 0.8319\n",
            "Epoch 36/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1353 - acc: 0.9469 - val_loss: 0.8125 - val_acc: 0.8673\n",
            "Epoch 37/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1434 - acc: 0.9610 - val_loss: 0.6859 - val_acc: 0.8673\n",
            "Epoch 38/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1126 - acc: 0.9570 - val_loss: 0.8805 - val_acc: 0.8319\n",
            "Epoch 39/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1202 - acc: 0.9596 - val_loss: 0.7404 - val_acc: 0.8761\n",
            "Epoch 40/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1060 - acc: 0.9759 - val_loss: 0.7777 - val_acc: 0.9115\n",
            "Epoch 41/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0851 - acc: 0.9706 - val_loss: 0.7892 - val_acc: 0.8850\n",
            "Epoch 42/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1110 - acc: 0.9701 - val_loss: 0.7234 - val_acc: 0.9027\n",
            "Epoch 43/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0847 - acc: 0.9621 - val_loss: 0.6520 - val_acc: 0.8850\n",
            "Epoch 44/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0998 - acc: 0.9699 - val_loss: 0.8311 - val_acc: 0.8850\n",
            "Epoch 45/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0961 - acc: 0.9703 - val_loss: 0.9380 - val_acc: 0.8761\n",
            "Epoch 46/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1220 - acc: 0.9706 - val_loss: 0.9948 - val_acc: 0.8673\n",
            "Epoch 47/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1620 - acc: 0.9581 - val_loss: 1.0755 - val_acc: 0.8496\n",
            "Epoch 48/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1339 - acc: 0.9545 - val_loss: 0.9025 - val_acc: 0.8496\n",
            "Epoch 49/80\n",
            "15/15 [==============================] - 21s 1s/step - loss: 0.1017 - acc: 0.9627 - val_loss: 0.9382 - val_acc: 0.8673\n",
            "Epoch 50/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1163 - acc: 0.9583 - val_loss: 0.9121 - val_acc: 0.8761\n",
            "Epoch 51/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0883 - acc: 0.9636 - val_loss: 0.9012 - val_acc: 0.8850\n",
            "Epoch 52/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0722 - acc: 0.9773 - val_loss: 0.9723 - val_acc: 0.8496\n",
            "Epoch 53/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0767 - acc: 0.9703 - val_loss: 0.8492 - val_acc: 0.8850\n",
            "Epoch 54/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0995 - acc: 0.9652 - val_loss: 0.8970 - val_acc: 0.8938\n",
            "Epoch 55/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0732 - acc: 0.9692 - val_loss: 0.8439 - val_acc: 0.8850\n",
            "Epoch 56/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1143 - acc: 0.9703 - val_loss: 0.8421 - val_acc: 0.8850\n",
            "Epoch 57/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0846 - acc: 0.9730 - val_loss: 1.0750 - val_acc: 0.8407\n",
            "Epoch 58/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0590 - acc: 0.9773 - val_loss: 0.9186 - val_acc: 0.8850\n",
            "Epoch 59/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0381 - acc: 0.9813 - val_loss: 0.8697 - val_acc: 0.8938\n",
            "Epoch 60/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0813 - acc: 0.9692 - val_loss: 0.8543 - val_acc: 0.8850\n",
            "Epoch 61/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0815 - acc: 0.9677 - val_loss: 1.0149 - val_acc: 0.8673\n",
            "Epoch 62/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0588 - acc: 0.9813 - val_loss: 1.0924 - val_acc: 0.8496\n",
            "Epoch 63/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0555 - acc: 0.9717 - val_loss: 0.8882 - val_acc: 0.8850\n",
            "Epoch 64/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1310 - acc: 0.9610 - val_loss: 1.0425 - val_acc: 0.8673\n",
            "Epoch 65/80\n",
            "15/15 [==============================] - 21s 1s/step - loss: 0.0897 - acc: 0.9747 - val_loss: 0.9637 - val_acc: 0.8673\n",
            "Epoch 66/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0781 - acc: 0.9759 - val_loss: 1.0154 - val_acc: 0.8584\n",
            "Epoch 67/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0724 - acc: 0.9746 - val_loss: 1.1058 - val_acc: 0.8761\n",
            "Epoch 68/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0480 - acc: 0.9826 - val_loss: 1.0984 - val_acc: 0.8673\n",
            "Epoch 69/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0607 - acc: 0.9799 - val_loss: 0.9930 - val_acc: 0.8761\n",
            "Epoch 70/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0614 - acc: 0.9799 - val_loss: 1.0923 - val_acc: 0.8761\n",
            "Epoch 71/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0755 - acc: 0.9759 - val_loss: 1.0956 - val_acc: 0.8850\n",
            "Epoch 72/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0383 - acc: 0.9853 - val_loss: 1.0058 - val_acc: 0.8761\n",
            "Epoch 73/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0528 - acc: 0.9728 - val_loss: 0.8493 - val_acc: 0.8761\n",
            "Epoch 74/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.1010 - acc: 0.9706 - val_loss: 0.6856 - val_acc: 0.8938\n",
            "Epoch 75/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0714 - acc: 0.9746 - val_loss: 0.8725 - val_acc: 0.8584\n",
            "Epoch 76/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0558 - acc: 0.9824 - val_loss: 0.9256 - val_acc: 0.8761\n",
            "Epoch 77/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0631 - acc: 0.9759 - val_loss: 1.0570 - val_acc: 0.8850\n",
            "Epoch 78/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0498 - acc: 0.9826 - val_loss: 1.1248 - val_acc: 0.8584\n",
            "Epoch 79/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0587 - acc: 0.9733 - val_loss: 1.0154 - val_acc: 0.8761\n",
            "Epoch 80/80\n",
            "15/15 [==============================] - 20s 1s/step - loss: 0.0527 - acc: 0.9826 - val_loss: 0.8094 - val_acc: 0.8673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GosuCdD3ZfFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "1d8a9636-64b6-4247-b0f6-96838a4159c7"
      },
      "cell_type": "code",
      "source": [
        "train_acc = history.history['acc']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_acc']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "\n",
        "epochs = range(len(train_acc))\n",
        "plt.plot(epochs, train_acc, 'b', label = 'Training_accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label = 'Validation_accuracy')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training_accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "\n",
        "plt.plot(epochs, train_loss, 'b', label = 'Training_loss')\n",
        "plt.plot(epochs, val_loss, 'r', label = 'Validation_loss')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training_accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4FFUXh9/ZvukBQgcFuzQBUZqU\nANJr6KLSRbEhIh8KggIKIkWQooCAgCBFwYCA9F6UItKUIlIUSEhPts98fwxZsiSbAhtCwn2fZx/I\nTrtnZ3d+9557zrmSoigKAoFAIBAI8g2avG6AQCAQCASCnCHEWyAQCASCfIYQb4FAIBAI8hlCvAUC\ngUAgyGcI8RYIBAKBIJ8hxFsgEAgEgnyGLq8bIBAUZEaOHMn+/fsBuHjxIkWLFsVoNAKwYsUKAgIC\nsnWeZs2asWjRIooUKeJ1n4kTJ1KyZEm6det25w0XCAT3NJLI8xYI7g7h4eF89tlnPP3003ndFIFA\nkM8RbnOBII948cUXmTx5Ms2bN+fQoUNER0fTp08fmjVrRnh4OPPmzXPv+9hjj3HlyhX2799Ply5d\nmDhxIs2bNyc8PJwDBw4A8L///Y8ZM2YAakdh6dKldOzYkbp16zJu3Dj3uWbNmkWtWrWIiIhg8eLF\nhIeHZ9nWw4cP06FDB5o1a0aLFi3Ys2ePe9uqVato2rQpTZs2ZciQIdjtdq/v79+/nyZNmriPTfv3\ntGnTGD58OB07dmT+/PnIssxHH31E06ZNCQ8PZ8iQITgcDgBiYmIYMGAAjRo1onXr1uzatYtt27bR\nqlUrj3Z36NCBTZs25ei+CAT5ASHeAkEecuzYMdauXUu1atWYOXMmpUuXZv369SxYsICJEyfy33//\npTvmxIkTVKlShXXr1tG9e3dmzpyZ4bl//fVXvv/+e1auXMmiRYu4cuUKp0+fZs6cOaxevZrvvvuO\n9evXZ6udH374IX369GH9+vX079+fkSNHAnDp0iXGjx/Pt99+y/r167FYLHz77bde38+K7du38/XX\nX9OzZ082btzIb7/9xpo1a1i3bh3Hjx/n559/BtQpgoceeojNmzczfvx4Bg8eTO3atYmKiuLUqVMA\n/Pvvv1y4cIF69eply0aBID8h5rwFgjykfv36aDRqH3r48OG4XC4AypQpQ1hYGJcuXaJEiRIex/j7\n+9O4cWMAKlSowPLlyzM8d+vWrdFqtRQrVozChQvz33//cfLkSZ555hmKFi0KQEREBFOnTs2ynatW\nrUKSJACqV6/OxYsXAdi9ezdVq1alWLFigCqqWq2WlStXZvj+wYMHM71OlSpVKFSoEABNmzalYcOG\n6PV6ACpVquS+7vbt25k9ezYATz75JJs3b8ZgMNC0aVPWrl3L448/zqZNm2jUqBEGgyFL+wSC/IYQ\nb4EgDwkODnb//48//nCPtjUaDVFRUciynO6YwMBA9/81Gk2G+wAewXBarRaXy0VCQoLHNVPFNSsi\nIyP59ttvSU5ORpZlUkNlYmNjCQoKcu+XGozn7f2sSNu2mJgYRo8ezYkTJ5AkiejoaF5++WUA4uLi\nPD6HVFtbtmzJsGHDGDx4MJs2baJPnz7Zuq5AkN8QbnOB4B5hyJAhNG3alA0bNrB+/XpCQ0N9fo2A\ngABSUlLcf1+7di3LY65evcrw4cMZO3YsGzZscI94AUJDQ4mNjXX/nZSURHR0tNf3UzsRqSQkJHi9\n7uTJk9HpdERGRrJ+/Xrq16/v3hYSEuJx/kuXLuFwOKhRowZOp5OtW7dy+vRpateunaV9AkF+RIi3\nQHCPcP36dSpWrIgkSfz4449YLBYPofUFlStXZv/+/cTExGC321m1alWWx8TExODn50f58uVxOp18\n//33ACQnJ1O/fn0OHTrEpUuXUBSFkSNHsmLFCq/vh4WFERUVxfXr13G5XERGRnq97vXr13n00Ucx\nGAycOnWKw4cPuz+P8PBwfvzxRwDOnDlDhw4dcLlcaDQaWrRowejRowkPD3e73AWCgoYQb4HgHuGt\nt95i4MCBtG7dmpSUFLp06cKIESO4cOGCz65RuXJl2rdvT/v27XnppZdo2LBhlsc8/vjj1KtXj6ZN\nm9KlSxfCw8N56qmnePHFFylevDgff/wxL7/8Mk2bNgWgV69eXt9/4IEHiIiIoF27dnTv3p2aNWt6\nvW7v3r1ZunQpzZs3Z/HixQwdOpTly5ezbt06hgwZwpUrVwgPD2fQoEF8/vnnmEwmQHWdX758mRYt\nWvjgExMI7k1EnrdAcJ+hKIo7+Gzbtm1MmTIlWyPw/EJ0dDTt27dn27ZtaLXavG6OQJAriJG3QHAf\nERMTQ82aNbl8+TKKorBu3TqeeuqpvG6WT5k6dSrdunUTwi0o0IiRt0Bwn7FkyRK++eYbJEmifPny\njB07lhUrVrjnkG9lwIABtGvX7i63MudER0fTpUsXHnvsMSZNmuR2owsEBREh3gKBQCAQ5DOE21wg\nEAgEgnyGEG+BQCAQCPIZ+abCWlRUok/PFxrqR2ysb3No85KCZE9BsgUKlj3ClnuXgmSPsOUmYWGB\nGb5/3468dbqCFYlakOwpSLZAwbJH2HLvUpDsEbZkzX0r3gKBQCAQ5FdyVbz/+usvGjduzKJFi9Jt\n27NnDx07dqRLly5Mnz49N5shEAgEAkGBItfEOyUlhdGjR1OrVq0Mt48ZM4Zp06axZMkSdu/ezZkz\nZ3KrKQKBQCAQFChyTbwNBgOzZ892rxuclosXLxIcHEyJEiXQaDTUr1+fvXv35lZTBAKBQCAoUOSa\neOt0Oq8VjqKioihUqJD770KFChEVFZVbTREIBAKBoECRb1LFQkP9fB615y0EP79SkOwpSLZAwbJH\n2HLvUpDsEbZkTp6Id9GiRYmOjnb/ffXq1Qzd62nxdc5fWFigz3PH85KCZE9BsgUKlj3ClnuXgmSP\nsMXz+IzIk1Sx0qVLk5SUxKVLl3A6nWzdupU6derkRVMEAoFAIMh35NrI+9ixY4wfP57Lly+j0+nY\nsGED4eHhlC5dmiZNmjBq1CgGDx4MQIsWLShXrlxuNUUgEAgEggJFrol3xYoVWbhwodftNWrU4Pvv\nv8+tywsEAoFAUGARFdYEAoFAcE9z+rSGlSt1OBy+OZ+iwOrVOs6dk3xzwjxAiLdAIBAIfMrFixLx\n8b4514YNWpo08ePVV800buzHvn13lnUky/Dee0b69TPTuLE/W7Zkfr7YWIiOzlrknU64fPnudQaE\neAsEAsE9hs0GkZE6xowxEBOT8+NdLpgxQ8+qVToUxfft84bFAkOGGKlePYBHHw0gPNyPDz4wEhmp\nIyoqZ8KmKDBzpp6XXjKjKNCqlYOTJ7W0aePH66+buHYt50LpcsHbb5tYsMBA+fIyDgd0725m7lx9\nun0dDvUzrFYtgGef9WfrVu8if/WqROvWflSr5p8tofcF+SbPWyAQ5F+SkmD/fi1167owGvO6Nfcm\nsgwHDmhZvlzHTz/piY9XRWDXLh0rVqQQEJC98zid8PrrJn74QRWk+fOdjBtn4/HH5dxqOgAnT2p4\n5RUTp05peewxF4UKKRw6pOXYMS2zZ6v7aLXpexIPPywTEeEkIsJBmTLqdocD3n3XyMKFBooVk1m0\nyEKVKjK//WZn6FATy5bpWb9ex7BhNnr1cqDJxjDU4YA33lA/l6pVXSxdmsLZsxpeesnMsGEmTp/W\nMGaMDZ0O9u7VMnSokVOntISGKiQnqyL/ySfq9dJy/LiGF180c+mShs6dHRQufHd6S5Ki3M1+2e3j\n65y/gpRHCAXLnoJkC+RPe1JSwGgE7S2DjVttcTjUl5+f93PFxEDnzn4cPaqlRAmZgQPt9OjhyPSY\nu8Gttvz+u4bJkw3UqeOiXTsnYWG582i02eDcOQ2XLklcvKj+e+mShkOHtFy4oKpQ8eKqoP33n8QP\nP+ipX9/JokWWTDs+YWGBXL6cyIABJtas0fP00y6KFJFZv16PTqfQr5+DIUNs2e4EJCWp99bplJBl\ntVOg1UKRIgq6NMM+RYF58/SMGmXEapXo08fOyJE2TCbV1sOHtezbp+XAAS0JCZ7XcLkkjh3TYLOp\nHZXatZ1ERDhZu9bEli1QqZKLhQstlCyppDkG5s/X8+mnRhISJOrVczJ9upVixbzfL7sd+vc38fPP\nemrUcLFkSQpBQeq2ixclevQwc/KkloYNnRQurLBihR5JUujRw8EHH9g4c0ZDz55moqM19Otn56OP\nVJHfuFFL//5mkpMlhg2z8fbbdqRbBt65lectxLuAUJDsKUi2QP6z56+/NLRu7Ye/v8Lrr9vp3t1B\naqXjVFuSk+Hbb/XMmGHAZpOYNMlKq1bOdOe6dk2iUyf1wVizppOjR7WkpEgUKSIzYICDXr3sBOZR\nIa2092X/fi3du5tJTFSfvFqtQni4i44dHTRr5sRsvv3rJCfDb79p2btXFbFDh7RYreldq/7+Ci1b\nOunUyUHdui60WlUwe/Uys2GDjjZtHHz1lTVdhyqVwMBA2rZ18ssvOmrXVsU+IEAVmGHDTFy4oKF4\ncZnPPrPSrJnLa3tlWR31LlpkyHC7VqtQsqRC6dIypUsrREVJbNumo1AhmSlTMj93RsTHw5o1epYv\n17Fnz81eQbNmDmbMsHrtbFy7JvHOOyZ++UVH4cIyU6daadIk/bVPn9bw4YdGNm/WUbeuk2+/taQ7\nZ2Ii9O9vZvNm9fqVK7sYP95K9eo3vRX//KOK/J9/amnUyEmdOk7GjDFiMMCXX1pp0yb99x+EeAvx\nzoKCZE9BsgXylz0xMdCsmT/nz2swGhVsNolixWRee83OSy85CA0N5LPPbHz1lZ7r1zX4+yvIMlgs\nEi+9ZOfjj23uEfV//0lERJg5c0ZL7952PvnERlwcfP21gTlzDCQkSAQFKdSv76RWLRc1a7p44gnZ\nqzj5mtT7snu3lhdeMGOzwYQJNlJSYPlyPb//rjYkIEBhyBAbr7ySPfcsQEICREbqWbFCx/79WpxO\nVawlSeHJJ2WqVXNRtuxNASxTRqZYMSVD2y0W6NLFzL59Ol56yc6ECbZ0o7uUFOjXL5CNG6FBAyfz\n51s8PBsWC0ybZmDaNAN2O0yebKV79/Rioyjw/vtG5s418NBDMo8+6kKnA50ONBp11Hv5suotuHJF\nQlHUhtStq45+S5S4Mzm5eFH1NISGGunRIzHLz1tRYO5cddRvt0v0729nxAgbCQkSq1bpWL5cz5Ej\n6ofasKH6uXjriDmdMGuWnpAQ6NbNkeG9SEiAfv3MbN2qinxYmMzChRaqVfM+JSHEW4h3phQkewqS\nLZC1PYoCkyYZCApS6NnTgT597MxdweGArl3N7Nyp4+23bfTt6+Crr/R8842B5GSJQoVkXC4N8fEQ\nHKzQr5+dfv3sXLumznWeOKHOdX71lZXAQIWICD/On9fw2muqGzWt4CQkwLx5BubP13P58s0ndFCQ\nwrPPuujb107DhjkbweWUsLBAvv8+hZ49zbhcMHu2lRYtbgran39qWLFCx6JFakclPNzJ1KlWihbN\n+JHpcMCWLVqWL9ezYYPO7QquVs1F7dpqB+WZZ1wEB+e8rQkJ0LatH8ePaxk0yEaXLg4uXbrpet+y\nRcfhw1qaNnUye7YFL2tCcfSohs6dzcTEaBg3zkrv3p7zt+PHG5g40cgTT7hYtSqF0FDvbXI44N9/\nJRISJJ580redrpw+A44dU7+Dp09rKVlS5upVCZdLQqtVaNDARadODlq3dvrkt+V0wtixRo4d0zB5\nspXSpTOXUCHeQrwzpSDZU1BssdvVh3n79n5YLN7tWbBAz5Ah6tP2iSdcfPaZjWefzV3hyoihQ43M\nm2egWTMH8+db3aOe2FiYPdvA7NkGDAaJV16xpXN3W60werSR2bMNGI0KISEKV69qeOcdG0OHpp8H\nTEVR4MIFye1S3rtXx99/qxdu1crB6NE2SpXKnUfUvn2BdOyooNHAvHkWGjXK+DO/dk3ijTdMbN2q\nIyxM5ssvre6OhaLA4cMali9XI7uvX1fb/sgjLjp18gzCulNSI5rPn894ONq5M0yalIghY2+3m5Mn\nNUREqPO3H31k5dVXVQH/6is9I0aYeOABmTVrUjKdQ85tbucZkJwMH35oZNEiPZUry3Ts6KB9e6fX\nztbdQoi3EO9MKUj23Ku2XLx4U2SuX5d4/XU7NWpk7C77+2+JAQPMHD6sJTwcFi5MzLDX//ffEg0b\n+qPXQ4sWTpYsUXfq3t3OiBH2uxa5Om+enqFDTTz5pIs1azKObHa51HsTE+P93vzyi5a33jJx/bqG\n999XA3hyyh9/aBg2zMiBAzr8/BTeecfOgAH2LEUpuyQmwpw5BiZMMGIwKCxcaOG55zLvLMmyKm5j\nxhhxOCQGDLATHKwGNp09q4ppkSIy7durc9ZVqsheOyx3wj//SIwfb0SrhVKlZMqUUV3vZcvK1KgR\nQHR09n43p0+rAn7lioZhw2yUKCHz5ptmihVThfuBB/Kv4Dkc5Jn3KiOEeAvxzpSCZM+9ZMsff2iY\nOdPAvn1aLl1KP+Lp3t3O8OF2ihS5+TNavlzHe++ZSE6WKF1a5tIlDb162Rk/3uZxrMsFbduaOXBA\nx6xZFjp0cPLrrxqGDFFd0KGhCv/7n43u3R05Tq86elTDjh1qalZWQrJzp5bOnc2Ehips2JCS6Ugx\nO/cmKkri/HnJa8cmO8gyLFum4+OPjURHa3jkERdTplgzPacsw+zZeo4f11K3rpMGDVweo66YGHW+\nfe5cA/HxEqGhsGBBCjVrZt/LcfSohv79zZw7p34XzGaF5s2ddOzooH59V56KRk5/N3//LRER4ef+\nXoeGKqxenZLrKWXZ4V56BtwpQryFeGdKQbLnXrElOlqiXj0/oqM1FC4sU7Omyx1YpaaGGDlxQktI\niMIHH9ho187BsGEmVqzQExCg3IjqddKuXSBHj5JujnHaNAOjRxtp08bB7NlWt8A6nTBnjp7x440k\nJ0uUKCHz+ut2Xngh6/SqAwc0TJ5sdEfNQnoXriyr87mpXoSNG3XY7bBypSVLIbvb9yYuDj791Mj8\n+Xr0epg40UqXLukDrex2eOstEytXeqpnpUouGjZ04nBILFigJyVFonBhNdJ9yBAjdnvObUlKUiPt\nCxVSo8PzKlr+Vm7n3ly6JNGhgx9RURIrV6ZkGnh1N7lXngG+QIi3EO9MKUj23A1bZJlMI1kVBXr1\nUvNChw+38cYb6edtnU745hs948YZSUqS3NHZ1aq5mDnTQrly6k8rJSWQp5+WiY2VWLZMddGeOKHh\n+ef9CAlR2L49JUP3+NWrEjNnqkFdadOrunVzYDJ57n/4sJYpUwzs2qWKdu3aTjp2dLJ9u5b1628G\nT1Wu7OLiRQ2xsTeNKVpUZvRoG+3bZ5zqkpa8+p7t2KGlTx8z8fESgwap8+ip9y8hQU2n2rlTR/Xq\nLj76yMqBA1q2blUjve121dbixW/mmPv7F6zfDNy+PRYLNzo1944UFKR7I8RbiHemFCR7ctuWpCRo\n1cqP0FCF+fMtGUb/Ll2q4803zdSu7eSHHyyZCv3VqxKjRhlZvVrHa6/ZGTrU7uE+DQsLJDIyhYgI\nM/7+EBmZwoABJo4f17J4cUqGualpuX5dYvZsPbNnG9x5yN5o2NDJoEF2jxF0atpSah5t2bI3vQi1\najkpV07J9vxsXn7PTp/W8MILZs6f19CmjYOpU63ExUl066bmkTdv7mDmTKuHdyI5Gfbs0ZKcLNGs\nmdMjCrsg/WagYNkjbPE8PiOEeBcQCpI9uW3LiBFGvvpKjX6qVMnFsmUWj1HHxYsSDRr4oyiwbVsy\nZctm7yfiLVAm1Z7vvtPx9ttmzGYFi0WiRw87kybZ0h/ghfh4Nb3q4MH0OTkhIQq9e9upWjVzt6fN\nxh2VJ83r71lMjDrK3rtXR5UqLqKiJP79V0Pv3nbGjrXlKF0pr23xNQXJHmGL5/EZIWqbC+4rDh/W\nMHu2nvLlZWrVcrJ4sYEOHcwsX26haFF1Pvitt0wkJkp88YUl28INWUe4du/u5NQpO7NmGShbVubj\nj7Mv3ADBwdxW9HZa8ntd8UKFYNkyC+++a+L779UPfMQIG6+/7j0dTSAoiAjxFtw3OBwwaJAJWZaY\nONFC7douzGY1bahdOzMrV1r46Scdu3bpaNbMQdeuWc8B55SRI22ULy9Tt64z2zWmBZ4YjTB1qpW6\nddU61I0b3/2ceIEgrxHiLbhvmDnTwIkTWl54wU6dOuoDf+xYG0YjTJ9uoHVrP65eVQPDJk5MX4LS\nF2i10LOnI+sdBZkiSWQYdS4Q3C8I8RbcF5w7J/H55wbCwmRGjrzprpYk+PBDGyaTwsSJqk/5q6+s\nubailEAgEPgCId6CfImiqLnKAQEKxYt7LlGY0b5DhpiwWiWmTbMSEuK5XZJg6FA7Dzwgk5IiedS3\nFggEgnsRId6CfEdUlMSbb5rchUhSlygsVermCk2lS6tlI8uUkdm9W8fOnTqef97pddk+IFfmuAUC\ngSA3EOItuKeIjpY4dAiefJIMV0batk3LwIEmoqI01KrlpEQJhYsX1dWV9u/Xsm9fxhPV/v4K48db\nRUSyQCAoEAjxFtwzKAr07Wtizx4ICgqgTRsHnTo5efZZF06nWiZz+nQDer3CqFFWBgzwXF/ZbleX\nKExdKjH13//+09C9uyPXVqcSCASCu40Qb8E9w/btWvbs0fH44xAXp7BokYFFiwyUKSMTEKBw8qSW\ncuVkvv7aQpUq6YuRGAzw4IMKDz4oUocEAkHBJpOijwLB3UNR1JE1wJIlcPhwMitWpNCli4OYGImT\nJ7V06eJg8+bkDIVbIBAI7ifEyFtwT7Bhg5bDh7W0aePgqaf0REVBvXou6tVzMX68GqSW12sMCwQC\nwb2CGHkL8hxZhnHjjGg0Cu+9l778p58fQrgFAoEgDUK8BXnOTz/pOHFCS0SEk0cfFS5xgUAgyAoh\n3oI8xemE8eON6HQK776bs4U6BAKB4H5FiLcgT1mxQsfZsxq6dXNQrpxwjQsEAkF2EOIt8DmyrEaP\nZ4XdDp9/bsRoVBg8+M6WuhQIBIL7CSHeAp+yerWOihX9ee01U5YCvnixngsXNLz8soOSJcWoWyAQ\nCLKLEG+BT4iPh9deM9Gvn5noaA0rV+qZM0fvdf+//tIwZowRPz+FN94Qo26BQCDICUK8BXfM7t1a\nGjTwZ8UKPVWruli1KoUiRWRGjTJy+HD6r1hMDPToYSYxUWLSJCvFiolR9z2F1Upo3Rr4jxiW1y0R\nCAReEOItuG0UBT7+2ECHDmauXJF4910ba9akULu2i5kzrTid0K+fmbi4m8c4HOp7589rGDTIRocO\nYiWvew3Dti3o/voT8zdfo7l6Ja+bIxAIMiBXxfuTTz6hS5cudO3alaNHj3ps27RpExEREXTr1o1F\nixblZjMEucT69Tq+/NLIgw8qrFmTwnvv2dHf8JTXr+/inXfsXLig4c03b85/Dx9uZOdOHc2bOxg6\nVLjL70WMkasAkBwOTPPn5nFrBAJBRuSaeB84cIB//vmH77//nrFjxzJ27Fj3NlmWGT16NLNnz2bx\n4sVs3bqVK1dEDz+/MX++qtTffGOhevX0xVXefddO3bpO1q/X8/XXer75Rs+8eQaefNLF9OlWjxXB\nBPcIdjuGDetwlSiJHBKCecFcsFq9768oqjtFIBDcVXLt8bl3714aN24MwEMPPUR8fDxJSUkAxMbG\nEhQURKFChdBoNNSsWZM9e/bkVlMEucD58xJbt+qoUcNFhQoZV0XTamHmTCthYTIffWTkgw+MFCki\ns3ChhYCAu9xgQbYw7NyGJiEeW5t2WF/shSY6GuOqlRnvLMsEvdCJ0Lo1kGJj7m5DBYL7nFwT7+jo\naEJDQ91/FypUiKioKPf/k5OTOX/+PA6Hg/379xMdHZ1bTRHkAt9+q466e/bM3PVdrJjCrFlWXC7Q\naOCbb6yUKSMC1O5VDJGrAbC1aoeldz8UrRa/r2ZkmLhvmjcH46Zf0P19joAP37/bTRUI7mvu2qpi\nSpofvyRJjBs3jvfff5/AwEBKly6d5fGhoX7odFqftiksLNCn58tr7pY9NhssXQqFC0Pv3mZMpsz3\n79AB1q0Df3+oW9cvW9cQ9yYPcDhg/VooUYLQFo3U3lZEBLplywg7cQgaNABu2HL+PIwZCaGhUKYM\npu+/w9TzRWjWLE9NyCn54r7kgIJkj7Alc3JNvIsWLeoxmr527RphYWHuv5955hm+++47ACZOnEip\nUqUyPV9sbIpP2xcWFkhUVKJPz5mX+NoeiwXM5oy3rVihIzrazMCBdhITbSRm47LVqqn/3nC+ZIq4\nN3mDfvtWQmJisPTpT9L1ZAB0L/cjdNkybJ9NJKFCddWWawkE9+yNITmZhHETcVaoROjz9ZH79iN2\nxz6UwKA8tiR73Ml9kaKjUUJCQJeL4x9FQbp2DaVYsWztnl++Z9nhju5NVBRKGq3Ja+70vngT/lxz\nm9epU4cNGzYAcPz4cYoWLUpAmonOvn37cv36dVJSUti6dSu1atXKraYIcsjcuXoefTSAH3/M+MGU\nGqj24osiWrwgYXS7zNu633M+/QyOqtUwrF+L5vzfAJiWLMKwfSu2Rk2wde6Gq2IlUt4ajPbyJfxH\nj8yTtt81FAXzjGkUrvQIIc3C3Z+Jr5Hi4wh6uTtFKj1CwJBBmQcNCtyYvplNkQoPYdiwLq+bkuvk\nmnhXq1aNChUq0LVrV8aMGcPIkSP54Ycf2LhxIwCdO3emd+/edO/enf79+1OoUKHcaoogB1y/LvHJ\nJ0ZsNom33jKlK7Jy4oSGAwd0NGjgpHx5MXddYHC5MP78E3KRIjhq1r75viRh6f8akqJgnvs1/Psv\n/h++jxwQSNLnX4AkAZAyaAjOx5/APH8u+t0788iI3EWKjyOo5wsEjPoAxWRGf/QIoY3rYVj/s0+v\nozt6hNBG9TCuX4vsH4B5wVxCWjdF8895n16noKE5/zcBH48AwLRsSR63JvfJ1WSdd999l6VLl7Jk\nyRIef/xxOnToQJMmTQB4/vnnWb16NatWraJNmza52QxBDpg0yUBiokTr1g5sNnjpJTP//Se5ty9Y\nkBqoJtKDChL6fXvQREdja9FKHcT2AAAgAElEQVRGTRNIg611O1zFS2Ba/C307o0mIZ7kkaORS6WJ\nVTEYSJwyHUWjIXDQ65Di22muvEb3x++ENq6Hcd0a7HXrEbPvMAlfzECy2wh+qSv+H3+orm97JygK\npm/nEdKyCdoL50l+Zwgxf/yJpVsP9L8fVjsK98GI8rZQFAIHv4mUkoJiNmPY/AskJ+d1q3IV7ahR\no0bldSOyQ0qKb120/v5Gn58zL/GFPefOSbz5pokyZRRWrrQQFKSwdq2effu0dOyoivkbb5gpUkRh\n/HhbruVp58t7oyhoz5xGKVw43ab8YI/fzGnoDx8kefgo5AfLeW7UapGsVoxbNsLZs9jrPEfy2M/c\no+5U5BIlkZKSMG7cgOZ6NEpAANqLF9wvKSEBpWj25m9zHbsd/7hoUvReAjvSYFq0gKDePdBcv07y\n2++SNGU6BAXhqlQZ2/PN0e/chnHDOvS7dyKXLIX28iUPuxWjiSxzI5OTCRz0Ov5TPkcJCiJh3iKs\nL/UGgxF785bIpUpj3PAzpuVLkaxWHHWe49YfYHa+Z1JUFJLVCn7ZCxzNC6SY6/hZk0jRZREJmwbT\nogX4zZ6F7flm2Ju1xLBrB87KT+F67PGcXfvaNSTZBUZjTpvtlTv9/fv7Z9wWUSZD4GbsWCNOp8Tw\n4TaMRnj1VQdduzo4ckTL22+bWLFCT1KSRI8ejlyN08mPmL6ZTaE6T2NYtzavm5JzZBnDmp+QQ0Nx\n1K6b4S6Wl3qjmExgNpM4aVo64UgleegHOMs/hHnhfELat/R4FQqvQ+Cbr+b5qFzz9zlCmoVD+fLo\n/vg90331e3YR+M4bKGYz8YuXkfL+hx5Baq4KFYnbuB1b63YY9u0hpFPbdHaHtn4+yzVy/Sd8imn5\nUhzVnyZ28y7sjZ732G7t/iKxP2/GWa48ftMm4z9uTM4Nl2VCWzQitPFzSAnxOT/+LqDfspFCtarB\nww9jWrQgW2sLa/69jP+o4ciBQSRNmIKtTTsAjGtXZ//CioJp3hwKV3uS4K4R2VvTOI8Rj2ABAAcO\naIiM1FO9uos2bVT3nyTBhAlWzp7V8OOPejZs0KHVKrzwgnCZe+By4TfzSwCMK5dhb94yjxuUM3S/\nHkB79QqW7i/irm97C0rhwsQvWkZIWDByufLeT2Y2E798NablS9O5kQ0bN2Bauhjd70dI+OZbXA89\n4kszsoVhbSSBb76KJjEBAOPK5TgrVfG6v/GHFQAkzPkWR70GGe6jBAaRMGcBxtU/oP3rT8/rbdyA\n/vfDaM+ewfWwd3sNG9ej+PkT9+PPeMu9dFWsRNzG7YQ2eg7z9C+wtWqD86lqmZnrge63X9HemDf3\n/+hDkiZ+ke1jcx2XC78Jn+A3+XP1O+jnR+A7b6Dfv5fE8ZO8ewoUhYD3BqFJTCBx0jTkEiWRi5fA\n9cCDGDasVwP9ssplTUoi8N03Md241/pf96M7sB/nszV9bKRvESNvAYoCo0apX/BRo2we3lCjEebN\ns1C6tExKikSzZk5KlLj3e6V3E8OGdWgvnAfAuGlDno8sc4pxjVrL3N66bab7Oeo1gHr1sjyfXKYs\nKe+8R8p773u84tb8gqVXX3QnjxPSpAGGn370RfOzh8OB/4fvE9zrBSSnQ/UeBAZiXPOT91GWO4gv\nTHVTZ4YkYWsXkc5m60u9ANDv2Ob1UM1//6I7/Rf2WrWzFBolKJjESdOQXC4C3xoI9uy7Y1Nr1svB\nIZgXzkO/c3u2j81NpKgogju3x3/SBOQyDxC3diMcPoyjajVM339HaPNwtGdPZ3isceUyjL+sx/5c\nA6wvvHTjhBK2Vm3RJCdh2LYl02tr/zxFaLOGmH5YgePpZ0iYMRsAv69n+NLEXEGIt4A1a3T89puW\nli0dPPusK932okUVFi608NxzTt55596eu/U5SUleHxypmGfPBMDWvBVSSgqGLZvuRst8g6JgXPMT\nclAw9uca5O61jEaSxk8iYeYcJFkmuO/L+H/wXo4E6HbQ/PcvIe1b4jfrS5wPP0Lsui1Ye7wMrVuj\nvXDeq+vcHcTXMn0QX3axP1cfAEMmQpkqoo5sfv6O5+pjebEXupPH8Zs6KXsNURSMa1YjBwUT/93y\nG4GFb9x5UJeioPvtQLbuoe7IIQyRqz1exqWLCW1UF8PObdiatSB203acVarCgw8S99MGLL37oTt5\ngpDG9THNmeV57OofCBg+FMXPj8RJUz1iMGw3OqKpHZaMMK5cRmjTBuj++pOUV14jbtXP2CI646hU\nBcPan9BcvOD1WCk2Bu2J4zn4oHyPEO/7HLsdRo82otMpjBhh87pfhQoyK1daqFQp4zrmBRKHg5C2\nzQmtUwPdwV8z3EX7x1EMu3dir9+QlMHvATdHsvkB3R+/o718CfvzzcBguCvXtEV0JvaXbTgffQy/\n2bMIadsczeVLuXIt/fathDaqi/7APqztOhD3yzZcT1ZQN3bsCNzMb7+V1Ae/LQuPRGbID5bDVfYB\n9Lt3gCt9xxhuCnuq0GeH5JEf4ypZCr/JE7IlIrrDB9X73LQ5zhrPYhn4FtoL5/EfNzrb18wIv8kT\nCG3RmJA2Tb2Lnd2O/4j/Efp8A4L7vOjxCnrzVTRR10j6cDQJC5aghNwsqY3RSNK4iSR89Q2SohD4\n/nuex/briSYmhuQPRiI/8KDHJZ1Vq+MqVVqNzs+gY6HfuZ2gV/uiaLTEz11I8uhx6vdfkrD0fxVJ\nljF/M9urPSHtW1GoQS3fZBncJkK873MWLtRz/ryGnj0dIm/7Fvy+nIL+j9+RZJnAtweqdWFv3efG\nqNvyyms4K1XBVfZBDL9syDdFNfTbtwFgb9Tkrl7X9ehjxK7fijWiM/qDv6oC60uPhSzjN3E8wZ3b\nIcXHk/jpBBK/mocSkKZaVbNmKH7+qvv+Vte5LGNYG4lcqJDXIL7sYn+uPpq4OHTHjqbfqCjod25H\nLlwYV4WK2T6nEhRM0udTkBwOAt9+LUsBMa75CVDT/gCS3/0fzocexvz1THS/7s++MWnQnjqJ38Tx\nKEYj+kMHCW38nJqilQbN5UuEtGuB31czcD76GEljx5P4yWcer7gNW7G8/la67IVUbO07ErN1N4mf\nfp7u2Pj532Hp80r6g1Jd5wnxGHZu89yWnEzgoDdQtFriV6xON11kaxeBHFZUDZi7sZhWWvy+mIju\nxDEUoxG/L6cQHNE6T9a9F+J9H+NwwLRpBvz8lPvPHZ4F2j9P4TdxPK5ixbF26oruz1P4TZ7gsY8U\nFYXxh+U4H3oYe3gT9YHRui2apEQM27fmUctzRuqDzV43+6M+nxEQQOKM2SR+NhkpKYngbhH4jR/r\ndYSaXaTr1wnuFoH/+LHIpUoTF7kBa59X0ouD2Yyt8fPo/j6XbvSaGsRna97qjkugOm6MqPU70rvO\ntefOoP33MvY69bxG8HvD3rgp1k5d0R85jHnWdO87KgrGyFXI/gHYG4Sr75nNJE5R53UD3x6Y886m\ny0Xg268hORwkzPmWxM+/QEpOJrhbR/zGjQaXC/2WTWqn7LcDWDt0JHb9Viz9XsXad4DHy1n5qSwv\nJ5crj7VP/3TH2lu08vq5pVYKNNziWfH/9GO0F85jee1NnNWeTn+g0YilZx808XHpir1oTxzHb8rn\nuEqUJGb/ETXLYO9uQsProt+1I5sfnm8Q4n0f8+OPOv79V8MLLzgoUiTNyCMlRe1B50G6hHTtGuza\nlfWODoda2So35ktTH0x2O0kTppA07nNcpUrjN3US2mN/uHczL5iLZLdj6TvA/QCxtVILDmU215Zd\ntKf/QvvnqSz3k6KjMX23ENPC+R4v46qVIGcyzWGzod+/F+fjT2S7frbPkSSsPfsQt3Yjcpmy+E8c\nT3CXDkgx12/rdLpDv6lzqFs3Y2vUhNhNOzJ+QN8gddRlXOP5gE+d+rgTl7n7Gjc6RoYd6Tt0qYLu\nyIHLPC1Joz9FLhKG//gx8OefGe6jO3YU7T/nsT/f1CMgzvlsTSx9+qM7/ReBg99M9/0xbFzv9Rlg\n/moG+kMHsXbohL1pc6wv9SLu5024yj6I/6QJhIbXIbhbBFJSEonjJ5E4c27Wue4+xlnjGVzFimNc\nt8a95rzuwH7Ms2fhfPgRkt/9n9djLS/3QTEY1HiW1N+Q0+nusCR9PgW5ZCkS5iwgacw4pNgYgju2\nwTx18t0wDRDifd+iKDB9ugGtVuGVVzwF0DznK4K7dcSYByUGA94fAvXqoT39V6b7mb6dd6Oy1Qif\nt8E8eyb6g79hbR+BvVkLlMAgEid+geR0qqMUpxNsNszz5iAHBWPt0t19rLPa0+pcmw86FkE9OhPS\nvmWWLtGAD4cR+PZAAge/6fEK6t8L4+ofvB6nP/grksWSo7nW3MJZpSqxm3Zga9ocw46tBL3WL8ed\nRyk6muAXOqG58h/Jw0aQsHg5SqH0RXPSYmv0PIrJ5CneqUF8wSE4fOCRUIoWxfnEk+gP7Es39XI7\n890e5y5UmMTxk5BsNujbN8POWtplXm8l+f2RuMo+gGn50nTfn+AXOhPU5yWkG2l1qWjPncF/3Gjk\nIkVIGvuZ+31n5aeI3bQdW7MW6E6eQC5dhrg1v2Dt1derSzxX0Wiwt2qDJjYW/Z5dYLUSOGggAImT\np3tfeQn1ntnad0R39gyGrep0jnnWdPRHDmPt1BV7kxur590oHxy3eh1y8RIEjBmJlJ3Vl3yAEO/7\nlK1btZw8qaVtWydly3o+JPWHDwJq7/qujr5dLtXdfMPNlxnGG2lG5tmz0B24vTm7jND8fQ7/T0cj\nFy5M0tibbnJHeBOsXbqjP3oE84ypGFf/gCbqmpqeknZEIUnYWrVBkxCPftftp+JIiQno/j6HJjpK\nffB4w2rFsP5nXKVKkzBjtvuVNHY8AMafvH+OqelL2Y1yzm2UkFASFizB3iAcw5ZNOe48BnwwRK2C\nNnIMKYOGZM8NHRCAPbwJuj9Pub0caYO7fBXEZ3+uPpLFgv63AzfflGX0u3fgKl0m89z5rM7duq3q\nIt61C9O8W4KsbvyWFD+/jOMaAgKI3bDN47uTMGM2CdO/xl6zNsY1qwlpUh/t8WPuNgcMegPJaiXp\n08/TVRRMvYdxKyOJ3bIrR3nouUGq69wYuRr/iePRnf4LS99XspXDben/KqA+B7VnT+P/2VjkImEk\njf403b7OGs8Su20PsZG/oBQp4lsjvCDE+z7lyy/Vh9LAgelHh6mBNfpjR9Hv23PX2qQ7egRNfBzg\nPQIYQLp6Ff2+PbhKlwFQe9O+CBCTZQLfeQPJYiHpkwnpfoRJH3+Cq2gx/Cd8qgbqaDRY+vRPdxpb\ny5sPjNslrechs/MYtm9Fk5SIrW0HbB27uF+WvgNwPvwIhi0bvaYDGXZuR9FocNSuc9vt9DkaDYkT\npyL7BxAw4n9IV69m6zDDurWYflyJo3oN90M3u7inOm6Mvt2rq7VOP1K9XVI7SPo0wVO6Y0fRxMaq\no+47HJkmfvo5FCpEwOhRaC78435fe+okurNn1JgML4VOlMKFPb47to5dsHXqSvwPa0h5/W10584S\n2jxcnZpZ8A2GvbuxNW+FrU37jBsjSTieq48SHHJHNvkCR83ayEWKYPxxBeYvp+Aq+wDJwz7M1rHO\nSlWw166LYdsWgnr1QLJaSRw/yas3RwkJVTsFd8nLIMS7AGBY/zOMG4d56iSPl+7IoQz3P3JEw65d\nOurXd6ZL/ZIS4tH+cx45rChwY/R9l3AXjQgIQHf8DzTnzma4n3HdGiRFwfLKa+45O/+J4+/4+qaF\n8zHs3omtWUts7SLSbVdCC5H02WQkmw3d3+ewN2+FXPaBdPs5n3lWnWv7OdI915ZT0lbqMq79yWsQ\nV6rgpJubvRE8J1ksqoDfgpSUiO7wQZxVq6EEBd9WG3MLuUxZkoePQhMXR+D/Bme5vxQfR8B7g1AM\nBhK/mJHjnGz7881QDAZVtBUFY+Rq5IBA7PUb3q4J6XDUroOi1WJIE7R2p/PdaVGKFYMpU5BSkgl8\n5023x+yO0t10OpI//Jj4b5eiGIwEvj2QgPeHIAeHkPTZpLxxhecUrRZbizZoEhOQXC61OE8O5t4t\n/dSOoO7USWyt2mZZyOhuIsQ7n6M9d4agl7vBsGEEjBnl8Qpp0wztuTPpjpk+XR11v/56BqPuG1G3\n1ojOOKpUxbBuzV1bitD9YBuhzmOnprfcintk1LKNe87O/OUUdEeP3Pa1NZcv4f/RCOSg4EwfTPYW\nrbC2V4U9ZcDrXk6mwd6y9c25tttAd8OF63zscdV1fmBfBo2xu13mGQVlpc5xZjQFod+7G8npzP3C\nLLeJtVdf1W279icMWUyh+I/8AO3VK6S8+z9cjz6W42spQcHYG4SjO3EM408/or1wXs17z6qsZk6u\nERiE86lq6A4fdM8hp0b6+0K8AejRA1vj5zHs2IppySJA7dwpRiP2Jk1v+7T2Zi2I3bQDR+WnkFwu\nNUiuWHHftPkuYIvoBIDlxZ5eS9x6w96sBc7yDyEXKqR6N+4hhHjnc8yzZyEpCowZQ9zSle5X0oej\nkaxWAga94RHEcv68RGSkjkqVXNSrl340p73hMndWqqwWK0hdxzm3sVrRH9iL84kK0Lcvik6XYbET\n6fp19Ht24qj+NHLpMmq60cSpN8tF3s5IV1EIePctNEmJ6oOpeIlMd0+c9hUx2/ZmOm+W6nL11gHJ\nCu1fqninDBoCkKGA6XdtRxMfp7p9M+hsuCpWwvVgOYy/bACLxfNYH476cgWNhqQpX6KYTAQOHew1\n+ly/dTPm7xbiqFiZlIFv3fblUudGA4a9q/7tQ5d5KvZ69ZFcLvR7d4Pdrkb6P/a474RQkkiaMAU5\nIBD/D99Hv2sHulMnsTds7JnffhvID5Yj7udNxOw8gK3rC75p713CUasOMVt2kzQ+m9Xo0qLVEvfT\nBmK37sm7jAwvCPHOx0jxcZiWLMZVshS89x6O8Cbul2Xgm9iat8Kwdzem+XPdx8yaZUCWJQYOtGc4\nuNTdCExxVqyMrW0HXEWLYVr8LVJSYq7aov/tAJLVir1efShUCEfdeuiPHE5Xtcm4fi2Sy+UROeuo\n3xBLj5fRHf8Dv2k5T9UwLluCcfNG7A3Cs/dgMhhuVunygnuuLROXd2bo/voTuUgYttbtkENC1E7A\nLZHE7sIbLb248m4UqpBSkrm1xrNh53YUkwlHjWdz3La7hav8wyQPHY4mOoqA4enTeqSkRALffQtF\np1Pd5V4WVckO9mYtUHQ6NNHRanBXw0Z30vQMuTnvvV2N9E9J8Xmkv1yqNMmjxqBJiCfoxa7AzTn9\nO8ZgyPESm/cKroqVbjtfXylaFLlESR+36M4R4p2PMX23CCklGUvv/ukeXFeuatjVfQquwBD8R49E\nc/EC0dESS5boKVNGdq8cdiu6Y3+gGI3qCkgGA9ZefdEkJmBcujhXbdHf4kL0NnJ1z+Hd8kBKHjUG\nV/ES+E0cj/bUyWxfV7p6lYAR/0P2V0fwPpvH02qxNW+NJjoKdu7M2bEpKWgu/IPzscdBr8fWvBXa\nK/+h+y1NiVanE+PPkbiKFcf5jHcBzqjGsxQVhe7EMRw1avrUNZwbWF55TV2gYsX3BAx+C/9Rw92v\noF490F68QMobb+OqVPmOrqOEhN787jVumivrXTuefgbFZMKwY3uuRvpbX+yJvW49NMlJKHq9GjUv\nKHAI8c6vOJ2Y58xCMZuxvviyxyaXC1q18qPxiw/RO3EKmuQkjtcZRNs2JiwWiVdftWfcCXU40J06\ngfOxJ9ydActLvVGMRsyzZ2Ve8OMOMezYjqLV4qilRj7bmrdC0Wg8RScuFv2ObTgqP5WulrESFEzS\n2M+QHA5Mixdk+7qB/xuMJi6O5OGjkMuU9YktqdhuzI0zalSOPjvd2dNIiuKev82okIh+zy40MTHY\nW7bONCXK+VQ1XKXLqDWeb+QYG3arlaDs9e5Rl3ladDoSp8xA8fPHvHAefjOmul+G7VtxVqhEyjtD\nfXKp1Hx9W+euPjlfOkwmHDVqojt5HONPP+ZepL8kqctjBgRib9rinoj6FvgeId75FMP6n9FevIC1\nUzeU0EIe2/bs0XLhgoaqVV3Et+nG7qCm1LNupPaZRZQsKdOtW8bzwtozp5FsNpwVK7nfU8LCsEZ0\nRvf3OQybNuSKLVJiArojh3BWrY4SGKRet0gRHLXV0oqafy+7bZacTq+Rs/bwxiiShC5NFbTMMESu\nwrj2J+w1a6uFJHyMo85zannN7dsxLfgm28el5hs7H1VdlPbnGiAHBqni7Y4izmY6U2qN58QEd4DU\nzVWs8oF4A64nnuT6r0eJ3bA1/Wv9FnXdWh9g69CJ64dPYH8+90aqqR0m3em/cFZ5KteEVX6wHDEH\nfidh+l2IVxHkCUK88ynmG+vNWvoNSLdtxQp11DxqlI3Zc2w8vm0Ssn8A3wQN4rfIs/j7Z3zO1Pzu\ntOKtXiO1WMFMXzXfA/2e3UguV7qRoLs28c+RwI2UKcDubQ7P3x9X+YdU8c6iuIwUc53AoYNRTCaS\npnyZ47rS2UKS1Mj1kBD8P/4QzaWL2TosNU3MPb9oNGJv2hztpYtq+p/LhfHnSOQiRXDUrJ3l+W6t\n8WzYsQ05KFhdejGfoISF4axaPd3LV8KdilyqtE/PdytpO0y5XRxHKVIk0ypigvyNEO+7jPbkCfwm\nfHpHy8jpjh7BsG8P9gbh6QJILBaIjNRRurTsXptbLl2G5A8/RpMQR6Hh73g/740Rq6ui5/yhq0JF\n7HXrYdi5zevSmJnicmGaNweDl8jrm/PdDTzet7dsjSJJGCNXIyUmYNi6GecTFXA99IjXSzkrVkYT\nH5elUAaMGIYmOorkocNxlX84R+bkBLlYcZg8GU1yEoGD38xWxTp3mtgjN9Oe3DEAkavRH9iHJuoa\ntuats5XT7Hy6Bq7iJTCuW6MuhPHPeXWlrNtco1pw+zirVEW+kVd/L5SlFeRfhHjfTVJSCH65G/4T\nPkWfwSIF2cX89c1lKG/ll190JCVJREQ4PAaT1pd746jxLMZ1a9D8fS7D87ojzTOIpE55XU3DCYlo\njXHlsmy3VYqOJrhrBwKHvkNQ/54eC3ukYti5HcVsxvH0Mx7vy8WK43ymJvp9e9SId7s9y2ITqV6D\nzFznUlIixpXLcD7xZIafoc95+WXsDRth2LoZ4/ffZbm79vSfyCEhKEWLut+zNwhH9g/AGLnKnTaW\n7cIbGo1asjUuDr9xY9Tz5Yf57oKIVoutdVtcJUrieCbrEp0CgTeEeN9F/MePRXv+bwCPSks5Qbp6\nFeOPK3A+/Aj2ho3TbU91mXfseMvIXqNR63DjJfdYUdAdP4rrgQczrLjlCG9C/JwFKBotQa/2JeC9\nQRmub50W3YH96gpP27fiqP6058IeqfZcu4bu5An1QZaBC9TWui2SouB/Q3SymuN1ucU7g7WTU9t1\n5DCSLGNv9PwdL/eYLSSJxM+/uFHyc1jma//abGj/Pofr0cc9I9/NZuzPN0X7z3nM3y1EDg3FUee5\nbDfBfuNzM61SFyq5V+qZ348kTZhCzP4jwqUtuCOEeN8ldAd/xfzVdFwPlkMxGG6WAs0h5gVzkRwO\nj2UoU4mOlti8WUvlyi4eeyx9dLOtWQsUrRbj2vS1sjVX/kNz/TrOit5Tbuxt2hO3cRvOJypgnj+X\nkFbPe9RRdqMomGd9SUi75miuXiFp+Cji1m7yWNgjFcOu1FWVGmR4TVtLdX5bSknB+cijWeaZprY/\n1YuQEamuf0cmS0X6GrlMWZJHfIQmPo6A997x6j7XnjuL5HKpaWK3kDp3LaWkYGvWMkd5zY5naiIX\nCQPAVaz4bVUiE/gIne6eT9ET3PvchWGHAJuNwLcHIskyiV/MwO+zT9Dv2YUUc91rkXspLpaAD4am\nW45Pv2c3cnAI1s7d0h2zerUOp1OiY8eMo8mVQoVx1K2nLmZx8YJHapQ7WK1CxUxNcT30CLHrNhMw\n7F3MSxYR2ug5HLU8g6Y0UVHoD/6KHFaUhK/nuUeISR9/gmHLJvwnfIq9eStcjzx6M/LZixtXLlUa\nR/Wn0R/8LVtuYrloMeQiYZm6zfU3xNv5dI0sz+dLrD37YFz9A8Z1azCsWe0eDadFd6OyWkbiag9v\ngmI2q8t45rTGslaLrWUbzAvm4qhbL3/UpRYIBF4RI++7gN/kz9D9eQpLr744atXB8Vx9JEVBv9t7\n8Q7T0sWYli/FuP5nj5cmIR7LgIEZFtdfsUKPRqPQvr33YDh34NNaT9d5qthlNvK+aZAfSV/MIHHK\ndCSHI10b9Qd/xf5cfWK37PJw7SqhhUi8sbBH4NsD1SVAd25HDg7BWamK18tZevZFDgjE1ikb+beS\nhLNCRbQXziPdWKHMA0VB/9uvuEqVzrIMqs/RaEiaPA1FktS8+Qy4NU3MA39/rF2643zo4duqSW59\n4UUUPz9sHTvn+FiBQHBvIcQ7l9H+cRS/qZNxlS5D8oiPgJtRppnNexsjV6NIEtf3HyH6zMWbr3OX\nSRmcvijFmTNw8KCWevVcFCvmPaLZXfxkjTfxrpTRYRli7f4i0X+e92zfmYtEn71E/MrIDGs221u2\nxtqmPfpf9+M/8n20F/5RBT6TyGdbl+5cP3c50yjztLhd5zcWWUmL5sI/aKKjcFS/u6PuVFzlH8ZR\nszb6/XsznPt2p4l5cWsnfTaZ2L2HbitFyvlUNaLPX1Hn+gUCQb5GiHdu4nCo7nKnk8SJU92LAzir\nVkcOCPRY2zctmv/+Rf/rfhy16iCXK48SFHzz5WWBgcU3qpd6c5mnooSF4ahVR003+u9f9/va438g\nh4TkPM/VaPRsX1Cwu9CKN5I+mYAcGorfjah5X6fMODMJWtMf+k3dJ4/EG9Q8dUlRMKyNTLdNd/pP\nZP8A5JKl8qBlAoEgvyDEO7eQZfzHjEL/x+9YuvXAkXahA50OR63a6M6dRXP5UrpDU4uSZDTH+9NP\nOg4f9rxtigKLFoGfn0x8JH4AACAASURBVEKLFlnnj99a/ERKSkT79zl1xHoX5kKVokVJGvuZ+++c\nLtOXFakj74zS0vIiWO1WUoPwbp26wOlEe+Y0rsceE3PSAoEgU4R45wJSzHWCenTGb+Y0XGUfIPmj\nsen2Sa20lFHUeWrpS3tLz0pihw5p6NvXTNOm/nTqZGbvXtXVfPCghjNnoHlzZ7bWmU9b/ARAe+IE\nkqLgrJB9l/mdYovojLVTV+x166mLoPgQ10MPo5hMGQat6Q/+iqLT4azsfY49t5FLlsLx9DPod+9E\nio52v689/zeSw6GmiQkEAkEmCPH2MbpDvxHauB7GTb9gb9iI2A3bUEJC0+2XGnBkuLG6UCrStWvo\n9+7GUePZdAFVmzeryQEPP+xi+3Ydbdv60bq1mc8/V+c/O3XK3lrWcvESOGs8i37fHjXPOpuR5j5F\nkkic/jXxP6zx/ShTp8P5xJPo/jzpub63zYbuj6OqWz2Pc2xtrdshyTLGdWvc72UarCYQCARpEOLt\nKxQF09yvCGndFM3lSyQP/YD4JStRCmecCuZ64knkIkXUkXeanF/jujVIipKhy3zbNh0ajcLPP6ew\ndm0yTZo42b9fx5YtOooWhXr1sr9utK11W7d46I7nINI8n+CsWBnJbkd7+i/3e7o/fkey2/N0vjsV\nW8vWgOdSne40scdEDrZAIMgcId4+wv+D9wgcNgQlOJj4ZavUiPDMFrvQaLDXrYf26hUPgXGvFtXK\nU7zj41W3ebVqMiEhUKOGzOLFFjZvTuaFF+xMmZKzYmHuedfI1eiOHUXR6wtU4Q7nk6oXIW3QWmqw\nWl5FmqdFLvsAjqeqot+1Ayk2Bkgz8n6k4NwHgUCQOwjx9gGa839jnvs1zkceJXbzLhz1G2bruNQS\nlalR51LMdfS7d+CoVh25dBmPfXfs0OFySTRs6BmQVqmSzOTJNrqlr9mSKXLpMmrxk9070J04rq7h\nbTDk7CT3MO50sTTz3u5gtXtAvAFsrdohOZ3qWtuA9vRfKGazz9cVFwgEBQ8h3j7APPdrJEUh5Z33\nkEuUzPZxt+Z7G9f/jORyYWuZkctcDU5r0OD2VyO7FVvLtkguF5LN5q4JXlBwVVAXV0mdEgDQH/wN\nuXBh5AfL5VWzPLC1SvV+rAKXC93pP3E+/KhY7UsgEGSJEO87REpKxPTdQlzFime5aMatyA+Ww1X2\nAfR7dqnVxlJXi7plvWpFUee7g4MVqlZNX7P8dkl7nZwUZ8kPKAGBOMuVV93mioJ09apaEKba0/dM\nGpZc/iGcFSph2LYF3YljSFZrgZq6EAgEuUeuivcnn3xCly5d6Nq1K0ePehbMWLx4MV26dKFbt26M\nHZs+lSq/YFy6GE1iAtbe/W7L7Wx/rj6a+Dj0O7dj2LENR6UqyOXKe+xz9qzExYsa6tVz+nQRLPnB\ncjgqPwUUrGC1VFwVK6OJjUXz7+V7ojhLRthat0VyODB/OQUgy4VXBAKBAHJRvA8cOMA///zD999/\nz9ixYz0EOikpiblz57J48WKWLFnC2bNnOXLkSG41JfeQZfy+noliNGJ5sddtnSI13ztg5AdIDkeG\nC05s26YqdoMG2Y8mzy4pg4dia9E6T4uW/L+9O4+zuez/OP4658zCLDLDDI3dFDNDRIgowiDadEdT\nlnYhrbcYcytaCFFKulWoO7oljNKdcndX45cae8laTLIzK2aY7cz5/v445mTMcgZzZubMvJ+Px/3I\n+Z5zvt/rg9t7rut7fa/LVRwrre3cXqkmq53Psdb8ua069ZiYiJSGy8I7Pj6e3r3t+02HhoZy6tQp\nMjIyAPD09MTT05OzZ89itVrJzMzkiisK7yFd2Xl9swbLn/vJuvsejLp1L+kcOd3s4e2x274Od1GP\niH3/vT28L5ysVhZybhnA6Q8/rpJbFP61TOp2PLZswjCZsLZrX8GtKijv6hZYw8IxnXtcUI+JiUhp\nuGxL0OTkZFqdmzQEEBgYSFJSEn5+fnh7e/P444/Tu3dvvL29GTBgAM2alTyJKCDABw+Psp3IExRU\n9DrhpfbhewDUHD+Wmpd6riB/aN0aduyA1q0J7FwwXLKz4ccfISwM2rUrefm0y66nEimTWm7qAoDv\nnh3w8xYID6du6EWu3V5GSqxn8CB46SXw8iKwQ5uLe+avAujvWeVVlepRLSUrt38ljPMWIsnIyODd\nd9/l66+/xs/Pj/vvv589e/YQFlb8kGFa2tkybU9QkD9JSemX/H3Lrp0EfvstOTd251T9pnAZ5/K9\n4UZ8duzgzC23cfaC86xbZ+HsWR9uvDGHpKTsYs9xufVUJmVWi1ct6gQGYvrqK0zZ2WReex0ZFfB7\n5KweS89bCHzpJayhV5GWllmOLbt4+ntWeVWlelRLwe8XxWXhHRwcTPJ56zYnJiYSFBQEQEJCAo0a\nNSIwMBCADh06sGPHjhLDu7Kp+b59R6zMEaMv+1xZDz2K+cQJMoc/VOi977+3jza4Ysi8yjOZsLZq\ng9e55+gr22S1fHnhEZwd83T5Lk8rIm7NZfe8u3btypo1awDYuXMnwcHB+J3bNaNBgwYkJCSQlZUF\nwI4dO2jatKmrmlLmTMnJ1Fi+lLymzciJ7HvZ58trfhXp73+IUa9eoffi4jzw8jLo0qXsJ6tVB+c/\nAlfZJqs5mEyceeElsv82uKJbIiJuwmU97/bt29OqVSuioqIwmUxMmjSJ2NhY/P39iYyM5OGHH2b4\n8OFYLBbatWtHhw7uM9u55qIP7MOwj44seQnUy5SYaGL7dgs33mjF19dll6nS8sPb5uunx7BEpMpw\n6T3vsWPHFnh9/rB4VFQUUVFRrry8a+TlUeOD+dj8a5F171CXXmrt2vxV1dTrvlT5z69b27XXymUi\nUmVU7mmtlZDnhngsx4+ROewBDD/Xzob86/lu3e++VHlh4ZwZG03uTT0quikiImVG4X2R8rdwvNil\nUC+WzWZfzzwoyEarVmW3JGq1YzJxdlxMRbdCRKRMaW3zi2Gz4fXlF9gCAsjteqNLL7Vrl5mkJDM9\neuS58ra6iIi4IcXCRfDYvAnL8WNk9xsAnp4uvdYvv9jvz2qWuYiIXEjhfRHyh8yLWn+8rO3aZf+j\nadVK4S0iIgUpvEvLMPD+chW2WleQc2MPl19u504zZrNBy5a63y0iIgUpvEvJ45etWA4fIqfvLeDt\n7dJrGQbs2mWheXMbPj4uvZSIiLghhXcpeX/xOQDZt7p+yPzoUROnTpmIiFCvW0REClN4l4Zh4P3F\nZ9h8/cjp0dPll8u/363wFhGRoii8S8GyYzuWA3+S06cv1Kzp8uvt2mWfaR4RoclqIiJSmMK7FLz/\nc25hlnIYMgf1vEVEpGQKb2cMA+9Vn2HUrElOz8hyueSuXWb8/AwaNTKcf1hERKodhbcTlj278UjY\nR06vPpTH1l5ZWbBvn5mIiDxMJpdfTkRE3JDC2wnv/+TPMr+9XK63d6+ZvDzNNBcRkeIpvJ3w/s/n\nGN7e5ET2LZfr7dyp+90iIlIyhXcJLNt/xWP3LnJu7oXhX6tcrqmZ5iIi4ozCuwQ+7/8TgKxhD5Tb\nNfNnmoeHq+ctIiJFU3gXw5SUhHfsMqzNQ+2T1crJrl1mGje24e9fbpcUERE3o/AuRs1/LcCUk0Pm\no6Morw21T5wwkZxs1pC5iIiUSOFdlOxsan4wH1utK8i6575yu6wWZxERkdJQeBfB+/NYzEmJZA0Z\nDn5+5Xbdv/bwVniLiEjxFN4XMgxqvvsOhtlM5sMjyvXSmmkuIiKlofC+gOeGeDy3byPnlluxNW5S\nrtfetcuMj49B06ZaFlVERIqn8L5Azffsj4dlPja6XK+bmwu//24mLMyGxVKulxYRETej8D6P+eAB\nvFZ/Qe41bcm9vku5XnvfPjO5uSYNmYuIiFMK7/PUXPAeJpuNzBGjKO9dQTTTXERESkvhnS8jgxof\nf4QtKJjsO/9W7pdXeIuISGk5De+EhITyaEeF89yyCfPpU2QNvhe8vcv9+vkzzcPDNWwuIiIlcxre\nTz75JPfeey8rVqwgMzOzPNpUIcxJiQDkNW1WIdfftctMSIiNgIAKubyIiLgRD2cf+PLLL/n999/5\n6quvGDZsGOHh4QwaNIg2bdqUR/vKjTkpCQBbUHCZnjcvD44fN3HokJnDh00cPmzm7Flo187G9ddb\nCQyE1FQ4dsxM797WMr22iIhUTU7DG6BFixa0aNGCrl278vrrrzN69GiaNGnClClTaNq0qYubWD7M\nyefCu25QmZ1z9mwvZszwwmotfvJbeHgeTZrY73NrprmIiJSG0/A+cuQIK1eu5D//+Q9XXXUVI0eO\n5MYbb2T79u0899xzLFu2rDza6XImR3jXLbNzLlniiacn3H57Lg0b2mjY0KBRIxseHrBpk4X4eAub\nN1vYvdt+v7ttW01WExER55yG97Bhw7j77rv517/+Rb169RzH27RpU6WGzvN73kZw2QybJyaa2L/f\nTK9eVubNyyr0fvfu9l52Tg78+quZw4fN9O+vYXMREXHO6YS1VatW0bRpU0dwL1myhDNnzgDw/PPP\nu7Z15ciclIhRowaGb9lsRLJpk7033alTyUPhXl7QoYONO++0amU1EREpFafhPWHCBJKTkx2vs7Ky\nGDdunEsbVRHMycn2+91ltDjLxo2lC28REZGL5XTY/OTJkwwfPtzx+sEHH+S7774r1cmnTp3Ktm3b\nMJlMxMTEOIbZT5w4wdixYx2fO3ToEH//+9+57bbbLrb9ZcMwMCcnYQ2PKLNTbtxowWIxuPZahbeI\niJQtp+Gdm5tLQkICoaGhAOzYsYPc3FynJ964cSMHDhxg6dKlJCQkEBMTw9KlSwGoV68eixYtAsBq\ntTJs2DB69ux5OXVcFlNGOqasrDKbaZ6VZb+Pfc01Nnx9y+SUIiIiDk7De8KECYwePZr09HTy8vII\nDAxkxowZTk8cHx9P7969AQgNDeXUqVNkZGTg51fwnvLKlSvp27cvvhWYcqaksn1M7JdfLOTmmjRk\nLiIiLuE0vNu2bcuaNWtIS0vDZDJRu3Zttm7d6vTEycnJtGrVyvE6MDCQpKSkQuG9bNkyFi5ceAlN\nLzvmc/f0jTJaoEX3u0VExJWchndGRgaff/45aWlpgH0YfcWKFaxbt+6iLmQYRqFjP//8M82bNy8U\n6EUJCPDBw6Nsp2MHBfnbf5GTDoBP04b45B+7DNu22f97yy01CSq7NV+cCiqDtlcWVakWqFr1qJbK\nqyrVo1pK5jS8n376aUJCQli3bh19+/blxx9/ZPLkyU5PHBwcXGCWemJiIkEXJFlcXBxdupRu3+y0\ntLOl+lxpBQX5k5RkD+0aCQfxB07X8Cf73LFLZRjw44++NG4Mnp5nODci73Ln1+PuqlItULXqUS2V\nV1WqR7UU/H5RnD4qlp2dzUsvvUSDBg0YP348H330EV999ZXTC3bt2pU1a9YAsHPnToKDgwv1sLdv\n305YWFhp2u9SjqVRy2DYfN8+M6mpZjp21JC5iIi4Rqlmm589exabzUZaWhoBAQEcOnTI6Ynbt29P\nq1atiIqKwmQyMWnSJGJjY/H39ycyMhKApKQk6tSpc/lVXKb8HcXKYsKa7neLiIirOQ3vO+64g08/\n/ZRBgwbRv39/AgMDadKkSalOfv6z3EChXvYXX3xxEU11HdO54f2yDG/1vEVExFWchnd+zxmgS5cu\npKSkEB4e7vKGlSdzchKGyYRRBqMAGzda8Pc3CA/XJiMiIuIaTu95n7+6Wr169YiIiHCEeVVhTkrE\nCAwEj1LtkFqslBQTCQlmrrsuT+uUi4iIyzhNq/DwcN58803atWuHp6en43hpZ4m7A3NyErbges4/\n6MSmTfafhXS/W0REXMlpeO/evRuAzZs3O46ZTKaqE965uZjT0rC2uuayT6XJaiIiUh6chnf+GuRV\nlTklf7Ja3cs+V/5mJO3bK7xFRMR1nIb3fffdV+Q97o8//tglDSpvZbWueXY2bNtmoVUrG6VYME5E\nROSSlWqFtXy5ubmsX78eHx8flzaqPOUv0HK565pv22YmO1ubkYiIiOs5De9OnToVeN21a1ceffRR\nlzWovJXVAi16vltERMqL0/C+cDW1Y8eOsX//fpc1qLyZy2iBFk1WExGR8uI0vO+//37Hr00mE35+\nfowZM8aljSpPf61rfunhfeyYie+/96BZMxsNGhTePU1ERKQsOQ3v7777DpvNhtlsf4Y5Nze3wPPe\n7q4shs3feMOL7GwTTz6ZXVbNEhERKZbTFdbWrFnD6NGjHa+HDBnC119/7dJGlSdT8uXNNj9wwMTi\nxZ40a2Zj8ODcsmyaiIhIkZyG9wcffMBrr73meL1w4UI++OADlzaqPJmTkzF8fLjU57tmzfLGajUx\nblw2VWhAQkREKjGn4W0YBv7+f20G7ufnV6XWNjcnJV5yr3vvXjOffupBeHgeAwday7hlIiIiRXN6\nz7t169Y8/fTTdOrUCcMw+OGHH2jdunV5tM31DANzchLW1pe2NOprr3lhs5kYNy4Hs9Mfg0RERMqG\n0/CeOHEiq1at4tdff8VkMnH77bfTr1+/8miby5nST2PKycF2CQu07Nxp5rPPPGnbNo/+/dXrFhGR\n8uM0vDMzM/H09OT5558HYMmSJWRmZuLr6+vyxrna5cw0nz7dC4AJE7KpQncRRETEDTgd7B0/fjzJ\n5xYyAcjKymLcuHEubVR5MSXZ6zIuMry3bjXz9deeXH+9lZtv1qIsIiJSvpyG98mTJxk+fLjj9YMP\nPsjp06dd2qjycqkLtEyb5g3AhAk56nWLiEi5cxreubm5JCQkOF5v376d3Nyq8TzzpQyb799vIi7O\ng65drdxwg3rdIiJS/pze854wYQKjR48mPT0dm81GQEAAM2bMKI+2uZz5EhZo+fxz+8Pc99xTNX6A\nERER9+M0vNu2bcuaNWs4duwYGzZsYOXKlYwaNYp169aVR/tc6q9h89LPNl+50gMvL4NbbtEMcxER\nqRhOw/uXX34hNjaW1atXY7PZePnll+nTp095tM3lzEkX1/Pes8fM7t0W+vXL5YorXNkyERGR4hV7\nz/v999+nf//+PPPMMwQGBrJixQoaN27MgAEDqszGJKbkJAyzGSMwsFSf/+wz+886d92lXreIiFSc\nYnves2fP5qqrruKFF16gc+fOAFVqWVSwD5sbgXXAYnH6WcOAlSs98fExiIxUeIuISMUpNrzj4uJY\nuXIlkyZNwmazMXDgwCozyzyfOSkJW0hIqT77669m9u83M3BgLlVgfRoREXFjxQ6bBwUFMWLECNas\nWcPUqVM5ePAgR44cYeTIkaxdu7Y82+gaOTmYT50s9f3u2Fj7rYKBA6vWDzAiIuJ+SrWdRseOHZk2\nbRo//PADPXr0YO7cua5ul+sllX6BFpsNPv/cg1q1DK2oJiIiFe6i9sLy8/MjKiqKTz/91FXtKT8n\nTgClm2m+caOFo0fNDBhgxdvb1Q0TEREpWfXdyDLRvrpaadY1X7nSPjVAQ+YiIlIZVPvwdtbztlrh\niy88qFvXRrduGjIXEZGKV33DO3/Y3MnqauvWWUhONnPbbVY8nC5pIyIi4nrVN7wdPe+6JX4sf2GW\ngQP1bLeIiFQOCu8Shs1zcuDLLz0JCbHRqZOGzEVEpHKovuFditnmCQlmTp0y0bOnFXP1/Z0SEZFK\nxqV3cadOncq2bdswmUzExMTQpk0bx3vHjh3j2WefJTc3l4iICF566SVXNqWwxEQMH19KWi7t0CH7\ncrBNmxrl1SoRERGnXNaf3LhxIwcOHGDp0qVMmTKFKVOmFHh/2rRpPPTQQyxfvhyLxcLRo0dd1ZSi\nJSY6nWl+8KD9t6dxY1t5tEhERKRUXBbe8fHx9O7dG4DQ0FBOnTpFRkYGADabjS1bttCzZ08AJk2a\nREgp1xgvE4ZhD28nq6sdOKDwFhGRysdl4Z2cnExAQIDjdWBgIEnnliRNTU3F19eXV199lXvvvZdZ\ns2a5qhlFMp06Cbm5TsM7f9i8USMNm4uISOVRbk8uG4ZR4NcnTpxg+PDhNGjQgBEjRhAXF0ePHj2K\n/X5AgA8eHs637iyVVPsQvXfDEIKC/Iv92NGj4OMD4eF+uMNuqCXV4m6qUi1QtepRLZVXVapHtZTM\nZeEdHBxMcnKy43ViYiJB53q6AQEBhISE0LhxYwC6dOnC3r17SwzvtLSzZdY2z9/2Uxs441+bs0np\nxX7ujz/8aNzYRnJy2V3bVYKC/EkqoRZ3UpVqgapVj2qpvKpSPaql4PeL4rJh865du7JmzRoAdu7c\nSXBwMH5+fgB4eHjQqFEj/vzzT8f7zZo1c1VTCjEl24fvS1rX/NQpOH3apCFzERGpdFzW827fvj2t\nWrUiKioKk8nEpEmTiI2Nxd/fn8jISGJiYoiOjsYwDFq0aOGYvFYebEH1wMeH3Lbti/2MZpqLiEhl\n5dJ73mPHji3wOiwszPHrJk2asGTJEldevljWzl3g9GmsqcUPh+eHd6NGCm8REalcqu+6YZaSJ78d\nPGifoda4sYbNRUSkcqm+4e1Efs+7SRP1vEVEpHJReBfj0CENm4uISOWk8C7GwYMmatUyqF27olsi\nIiJSkMK7CIZhHzZXr1tERCojhXcRUlJMnD1r0mNiIiJSKSm8i6CZ5iIiUpkpvIuQP1lNPW8REamM\nFN5F0FagIiJSmSm8i6CtQEVEpDJTeBdB65qLiEhlpvAuwsGDZurUsXFuEzQREZFKReF9AZsNDh/W\nVqAiIlJ5KbwvkJhoIjtbz3iLiEjlpfC+QP5Mc/W8RUSkslJ4XyB/prl63iIiUlkpvC+grUBFRKSy\nU3hfQM94i4hIZafwvkB+z7thQ/W8RUSkclJ4X+DAATPBwTZq1qzoloiIiBRN4X0eqxWOHjVpNzER\nEanUFN7nOXbMhNWqZ7xFRKRyU3ifR1uBioiIO1B4n+fgwfxnvDVsLiIilZfC+zx/ra6mnreIiFRe\nCu/zaNhcRETcgcL7PAcPmjCZDBo00LC5iIhUXgrv8xw6ZCYkxMDLq6JbIiIiUjyF9zk5OfnPeGvI\nXEREKjeF9zmHD5swDJPWNBcRkUpP4X3OkSNa01xERNyDwvuc1FT7M95BQep5i4hI5abwPiclxR7e\ngYEKbxERqdwU3ufk97wV3iIiUtkpvM9ReIuIiLtQeJ+TH9516ii8RUSkcvNw5cmnTp3Ktm3bMJlM\nxMTE0KZNG8d7PXv2pH79+lgsFgBmzpxJvXr1XNmcEuXf8w4IUHiLiEjl5rLw3rhxIwcOHGDp0qUk\nJCQQExPD0qVLC3zm/fffx9fX11VNuCipqSZ8fAxq1qzoloiIiJTMZcPm8fHx9O7dG4DQ0FBOnTpF\nRkaGqy532VJTTRoyFxERt+CynndycjKtWrVyvA4MDCQpKQk/Pz/HsUmTJnHkyBGuu+46/v73v2My\nmYo9X0CADx4eljJtY1CQv+PXqakQEVHwmLtx57ZfqCrVAlWrHtVSeVWlelRLyVx6z/t8hlGwV/vk\nk09y4403csUVV/D444+zZs0a+vXrV+z309LOlml7goL8SUpKB+DsWcjM9KdWLStJSZllep3ycn49\n7q4q1QJVqx7VUnlVpXpUS8HvF8Vlw+bBwcEkJyc7XicmJhIUFOR4feedd1KnTh08PDy46aab+P33\n313VFKf0mJiIiLgTl4V3165dWbNmDQA7d+4kODjYMWSenp7Oww8/TE5ODgCbNm3i6quvdlVTnNJj\nYiIi4k5cNmzevn17WrVqRVRUFCaTiUmTJhEbG4u/vz+RkZHcdNNN3HPPPXh7exMREVHikLmraWlU\nERFxJy695z127NgCr8PCwhy/vv/++7n//vtdeflS07C5iIi4E62whobNRUTEvSi80bC5iIi4F4U3\nGjYXERH3ovBG4S0iIu5F4Y3CW0RE3IvCG/s971q1DDw9K7olIiIizim8sfe81esWERF3Ue3D2zC0\no5iIiLiXah/eGRmQm6uet4iIuI9qH956xltERNxNtQ9vzTQXERF3o/DW0qgiIuJmqn14a9hcRETc\nTbUPbw2bi4iIu1F4K7xFRMTNKLx1z1tERNxMtQ9v3fMWERF3U+3DOzXVhMlkULu2wltERNyDwjvV\nRECAgcVS0S0REREpHYW3NiURERE3U63D22ZTeIuIiPup1uF96hTYbApvERFxL9U6vPWYmIiIuKNq\nHd56TExERNxRtQ5vra4mIiLuSOGNhs1FRMS9VOvwTkmxl6+et4iIuJNqHd4aNhcREXek8EbhLSIi\n7kXhje55i4iIe6nW4Z2SYsJiMahVq6JbIiIiUnoeFd2AipS/NKrJVNEtERGpXObMeYPffttNamoK\nWVlZhIQ0oFatK5g69bUSv7d69Rf4+vrRvfvNRb7/5puzGDQoipCQBq5odrVR7cO7fn1bRTdDRKTS\neeKJZwB7GP/xRwJjxjxdqu/1739bie8/9dTfL7ttUo3D22qFkydNRETofreISGls3bqZTz5ZzNmz\nZxkz5hl+/nkLcXHfYrPZ6NKlKw89NIIFC96ldu3aNGsWSmzsp5hMZg4c2E+PHr146KERjBkzgmef\nHcf333/LmTMZHDx4gCNHDvPkk3+nS5euLF78IXFx/yM4+EqsVitRUUNo375Dke3573+/YvnypVgs\nZpo2DWX8+H9gtVp55ZVJnDhxDC8vbyZOfJGAgMBCxzZt2uD4oeTs2bMMH34Py5d/QVTUQDp37kpA\nQAA33HAjr78+HQ8PD8xmMy+/PI1ata7g44//RVzct5hMZkaOHMP69T/RuHFjbr31TgCGDh3E3Lnv\nc8UVtV32Z1Ftwzs11f5fzTQXkcps8mRvvvjC+T/VZjPYbL6lOudtt1mZPDn7ktqTkLCPJUti8fLy\n4ueft/DOO/Mxm80MHnwH99xzX4HP7tq1k3//ewU2m41Bg27joYdGFHg/MfEEM2e+xfr1P/H55yto\n1ao1sbHL+Oab0A+VCwAAFxFJREFU/3LgwHGiou4iKmpIsW3JzMxk1qw5+Pv78/jjj5KQsI9du3ZQ\np04dJk+ewv/+t4Z16/4PDw+PQse8vb2LPKfVaqVz5xvo3PkGNm1azzPPPEeLFmHMnz+P//73K66/\n/gbi4r7l3Xc/5OjRIyxe/CGDB9/LnDlvcOutd7J//x+EhDRwaXCDi8N76tSpbNu2DZPJRExMDG3a\ntCn0mVmzZvHLL7+waNEiVzalkORk+38V3iIipXfVVVfj5eUFQI0aNRgzZgQWi4WTJ09y+vTpAp9t\n2TKMGjVqFHuuNm2uBSA4OJiMjAwOHz5E8+ah1KhRg8DAOoSHtyqxLbVq1WLCBPsw/IED+zl16iS/\n/baHDh06AtC7d18AZs6cVujY6tVfFHveiAj7dQMC6vDPf84hOzuL5OQkIiP78fvvvxER0Rqz2UzD\nho2Ijn4egIyMdNLS0li3bi2Rkf1KbHdZcFl4b9y4kQMHDrB06VISEhKIiYlh6dKlBT6zb98+Nm3a\nhKenp6uaUaz88NZjYiJSmU2enF2qXnJQkD9JSWdc3p78f6+PHz/G0qUfs3Dhx/j4+DBs2OBCn7VY\nLCWe6/z3DcPAMMBs/ushqJImE+fm5vL66zP48MN/U6dOXcaNe/rcOc3YbAX/XS/qmOm8k1ut1gLv\neXjYa3zzzZkMGXI/nTvfwL//vYjMzLNFngsgMrIfa9d+x+bNm5g+/fUS6y4LLntULD4+nt69ewMQ\nGhrKqVOnyMjIKPCZadOm8cwzz7iqCSVSz1tE5NKdPHmSgIAAfHx8+O23PRw/fpzc3NzLOueVV17J\nH38kkJubS1paGnv27C72s2fPnsFisVCnTl1OnDjOnj27sVqthIVFsHXrJgB+/PEHPvpoYZHHfHx8\nSUmxB8Gvv/5S5DVOnTpJgwYNycnJYf36H7FarbRsGc727duwWq2kpqYwYcJYwN6jX736C+rWrVPi\naENZcVnPOzk5mVat/hryCAwMJCkpCT8/PwBiY2Pp1KkTDRpUzOMCCm8RkUt39dUtqFnTh1GjHuKa\na67ljjvuYtas6bRp0/aSzxkYWIfIyH4MGjSIBg0aExHRqtje+xVX1KZjx+t55JHhXHXV1dx33zDe\neut1Fi5czObNG88N53swceJkatcOKHTMx8eHjz5ayJgxI7jhhm6YTIX7sn/72z1MmDCWBg0a8Le/\n3cMbb8ygZ89I+vbtz5gxIzAMg8cee9zR9po1fejd2/VD5gAYLjJx4kTjm2++cbyOiooy/vjjD8Mw\nDCMtLc0YMmSIkZOTYxw6dMgYOnSo0/Pl5lrLtH1TphgGGMZXX5XpaUVE5DKsWLHCyM7ONvLy8oz+\n/fsbx44dq+gmlUpKSooxcOBAIy8vr1yu57Ked3BwMMn53VsgMTGRoKAgANavX09qaipDhgwhJyeH\ngwcPMnXqVGJiYoo9X1ra2TJtX3KyPwAWyxmSktz/WW/7/a70im5GmahKtUDVqke1VF5VpZ4//zzC\n4MGDMZks9OzZh99+289TTxW+vdqrVx8GDry7AlpY2P/9XxwLFrzLE088Q0pKwXkHl/vnEhTkX+Rx\nl4V3165dmTNnDlFRUezcuZPg4GDHkHm/fv3o188+tHD48GEmTJhQYnC7gobNRUQqn2HDHuDZZ58o\nEHhvv/1eBbbIuZtu6sFNN/Uo12u6LLzbt29Pq1atiIqKwmQyMWnSJGJjY/H39ycyMtJVly01hbeI\niLgrlz7nPXbs2AKvw8LCCn2mYcOG5f6MN9jD29vbwLd0axqIiIhUGtV2V7HkZLQpiYiIuKVqH94i\nIiLuplqGd3Y2pKcrvEVEivPYYw8WWiRl3ry3WbJkcaHPbt26mYkTxwEQHf1sofdXrFjKggXvFnut\nffv2cvDgAQAmTZpAVlbW5TS9WqiW4Z2WZh8r19KoIiJFi4zsy3fffVPgWFzcd/Tu3afE702bdvFL\ng65d+x2HDh0E4MUXXy2XFcrcXbXcVSwlxR7e6nmLiBStV68+jBr1MKNHPwnAnj27CQoK4s8/9zNx\n4ng8PT3x9/fnpZemFfjegAG9+PLLb9m8eSNvvTWLwMA61KlTl5CQBlitVqZMmUxSUiKZmZk89NAI\n6te/ks8/j2Xt2u8ICAjghRcmsHr1lyQmnuDVV18iNzcXs9lMdPTzmEwmpkyZTEhIA/bt20uLFi0d\nG4MUZcmSxYW2LE1PT+ellyZy5swZ/Pz8mDx5Knl5eYWOLVmyiNq1a/O3v93DH3/s4/XXZ/D22+8R\nFTWQFi3C6NTpeurVu5L58+cV+L3w9PRk9uyZ7Nq1A4vFwtSpr/DGG29x++0D6dChEzk5OQwdOoh/\n/3sFHh6XHsHVMrxTUxXeIuIefCdPxPuLz5x/0GwisIgNM4qSfdudnJn8SomfCQgIJCSkAbt27SAi\nojXfffcNkZH9SE9PZ9KkVwgJacDLL7/Ahg3x+Pj4FPr+u+++zfPPv8zVV7dg7NgnCQlpQHr6aTp1\n6swtt9zKkSOHef75aBYuXMz113ehR49eRES0dnx//vx53HrrHfTq1Yfvv/8fCxe+x8MPP8Zvv+3m\nxRenEhAQyMCB/UlPT8ffv+iFTIBCW5YuWbKITp26MGhQFEuXfszmzRvZs2dXoWPFOXr0CFOnzqR5\n81C+++5/hX4vvL29SUw8wXvvfcgvv2xl9erV9O3bn2+//YYOHTqxZctGOne+4bKCG6p5eGvYXESk\neJGR/fj222+IiGjNjz/+H//850L27fud6dNfIS8vj6NHj3DddR2LDO9jx45x9dUtALj22vZkZ2fj\n71+L3bt3smpVLCaTmdOnTxV77d9+283IkWMAaN++Ax9+OB+ABg0aUadOXQDq1g3izJmMYsO7qC1L\nf/99D488MgqAe+6x7xW+alVsoWN79/5WzDlr0rx5KAC1a9cu9HuRlpbKNde0ddQdGdmdY8fS+Oc/\n38JqtfLDD2vp3/+2YusurWoZ3sHBBt7e0Lq1+y+LKiJV25nJrzjtJYN9Gc3UMl4etXv3m/noo4VE\nRvalUaPG1KpVi1dffZnXXptN06bNeP316cV+9/ytPQ3D3lH65puvOX36NHPnzuf06dM88siwEq5u\ncnwvN9fq2Djkwo1K8j9zoeK2LDWbLRhGwX/7izpW3Jahnp5/xWZRvxdFncvDw4OOHTuzefNG9u//\ng9at25RQd+lUywlrXbrkkZ4O11+fV9FNERGptHx8fAkNvZqPPvqAyEj7ktZnzmRQr1590tPT2bp1\nS7HbgNatG8TBg39iGAY//7wFsG8jeuWVIZjNZtau/c7xXZPJRF5ewX+Pw8Mj2Lp1MwC//LKFsLDw\ni2p7cVuWhodHsGWLfXvQzz5bwVdf/afIY76+vo79OYrbMrSo34vz2/3773t48cUXAejbtz8LFsyj\nXbvrLqqO4lTL8AY4t5+8iIiUIDKyH5s2baBbt5sAuOuuQYwa9TAzZkxhyJDhLF78oWNf7PONGDGa\niRPHM378MwQH1wOgR4+e/PTTDzz11Chq1qxJcHAwH3zwPm3btmP27NcK3Gt+5JGRfP31ap58ciSr\nV/+Hhx9+7KLaff6Wpd9++1/HlqWDBt3Ljh2/MmbMCH76aR3du99c5LHu3Xuybt1ann56NBkZGUVe\no6jfi4YNG9OkSTNGj36E2bNnEhUVBUBYWDinT592/BB0uUxGcWMOlUxZ75ZTVXbgyVeV6qlKtUDV\nqke1VF5VqZ6qWMvBgweYNWs6b775zkV/vyjV8p63iIhUDevWreWTTz4udHzQoHvp3v3mCmhRYZ99\ntpxVq1byj3+8WGbnVHiLiIjb6tatO926da/oZpTozjvv5s47y3bv8Wp7z1tERMRdKbxFRETcjMJb\nRETEzSi8RURE3IzCW0RExM0ovEVERNyMwltERMTNKLxFRETcjNssjyoiIiJ26nmLiIi4GYW3iIiI\nm1F4i4iIuBmFt4iIiJtReIuIiLgZhbeIiIibqZb7eU+dOpVt27ZhMpmIiYmhTZs2Fd2ki/b7778z\nevRoHnjgAYYOHcqxY8cYN24ceXl5BAUF8dprr+Hl5VXRzSyVGTNmsGXLFqxWK4899hjXXHONW9aS\nmZlJdHQ0KSkpZGdnM3r0aMLCwtyylvNlZWVx6623Mnr0aLp06eKW9WzYsIGnnnqKq6++GoAWLVrw\nyCOPuGUt+VatWsX8+fPx8PDgySefpGXLlm5Zz7Jly1i1apXj9Y4dO1iyZAmTJ08GoGXLlrz44osV\n1LqLc+bMGcaPH8+pU6fIzc3l8ccfJygoyDW1GNXMhg0bjBEjRhiGYRj79u0zBg8eXMEtunhnzpwx\nhg4dakycONFYtGiRYRiGER0dbaxevdowDMOYNWuW8fHHH1dkE0stPj7eeOSRRwzDMIzU1FSje/fu\nblvLl19+abz33nuGYRjG4cOHjT59+rhtLed7/fXXjbvuustYsWKF29azfv1644knnihwzF1rMQz7\n/1f69OljpKenGydOnDAmTpzo1vXk27BhgzF58mRj6NChxrZt2wzDMIxnn33WiIuLq+CWlc6iRYuM\nmTNnGoZhGMePHzf69u3rslqq3bB5fHw8vXv3BiA0NJRTp06RkZFRwa26OF5eXrz//vsEBwc7jm3Y\nsIFevXoBcPPNNxMfH19RzbsoHTt25M033wSgVq1aZGZmum0t/fv359FHHwXg2LFj1KtXz21ryZeQ\nkMC+ffvo0aMH4L5/z4rizrXEx8fTpUsX/Pz8CA4O5uWXX3brevLNnTuXRx99lCNHjjhGRN2ploCA\nAE6ePAnA6dOnqV27tstqqXbhnZycTEBAgON1YGAgSUlJFdiii+fh4UGNGjUKHMvMzHQMkdWpU8dt\narJYLPj4+ACwfPlybrrpJretJV9UVBRjx44lJibG7WuZPn060dHRjtfuXM++ffsYOXIk9957Lz/+\n+KNb13L48GGysrIYOXIk9913H/Hx8W5dD8Cvv/7KlVdeicVioVatWo7j7lTLgAEDOHr0KJGRkQwd\nOpRx48a5rJZqec/7fEYVXB3WHWv63//+x/Lly1m4cCF9+vRxHHfHWj755BN2797Nc889V6D97lbL\nZ599xrXXXkujRo2KfN+d6mnatCljxozhlltu4dChQwwfPpy8vDzH++5US76TJ0/y9ttvc/ToUYYP\nH+7Wf9fA/sP7wIEDCx13p1o+//xzQkJCWLBgAXv27OHxxx/H39/f8X5Z1lLtwjs4OJjk5GTH68TE\nRIKCgiqwRWXDx8eHrKwsatSowYkTJwoMqVd2P/zwA/PmzWP+/Pn4+/u7bS07duygTp06XHnllYSH\nh5OXl4evr69b1gIQFxfHoUOHiIuL4/jx43h5ebntn029evXo378/AI0bN6Zu3bps377dLWsBew+u\nXbt2eHh40LhxY3x9fbFYLG5bD9hvY0ycOBGTyeQYegbcqpatW7fSrVs3AMLCwsjOzsZqtTreL8ta\nqt2wedeuXVmzZg0AO3fuJDg4GD8/vwpu1eW74YYbHHX997//5cYbb6zgFpVOeno6M2bM4N1336V2\n7dqA+9ayefNmFi5cCNhvz5w9e9ZtawGYPXs2K1as4NNPP2XQoEGMHj3abetZtWoVCxYsACApKYmU\nlBTuuusut6wFoFu3bqxfvx6bzUZaWprb/107ceIEvr6+eHl54enpSfPmzdm8eTPgXrU0adKEbdu2\nAXDkyBF8fX0JDQ11SS3VclexmTNnsnnzZkwmE5MmTSIsLKyim3RRduzYwfTp0zly5AgeHh7Uq1eP\nmTNnEh0dTXZ2NiEhIbz66qt4enpWdFOdWrp0KXPmzKFZs2aOY9OmTWPixIluV0tWVhb/+Mc/OHbs\nGFlZWYwZM4bWrVszfvx4t6vlQnPmzKFBgwZ069bNLevJyMhg7NixnD59mtzcXMaMGUN4eLhb1pLv\nk08+Yfny5QCMGjWKa665xm3r2bFjB7Nnz2b+/PmAfX7CCy+8gM1mo23btkyYMKGCW1g6Z86cISYm\nhpSUFKxWK0899RRBQUEuqaVahreIiIg7q3bD5iIiIu5O4S0iIuJmFN4iIiJuRuEtIiLiZhTeIiIi\nbkbhLVKODh8+TMuWLQvsogTQs2fPMjl/y5YtCywK4Qpr1qyhV69eLFu2rMDx6Oho+vbty7Bhwwr8\nLzU1tcyuPWzYMH766acyO5+Iu6p2K6yJVLSmTZsyd+5cevbs6ZYLBK1du5aHH36YQYMGFXrvkUce\nKfK4iJQthbdIOQsODqZbt2688847jBs3rsB7sbGx/PTTT8ycOROw9zRHjRqFxWJh3rx51K9fn+3b\nt9O2bVtatmzJN998w8mTJ3n//fepX78+APPmzWP9+vWcOXOG6dOn06JFC/bs2cP06dOxWq3k5uby\nwgsvEBERwbBhwwgLC2P37t3861//wmKxONoSFxfH3LlzqVGjBjVr1uTll1/m559/Zu3atWzZsgWL\nxcI999xTqprnzJnDoUOHSEtLIykpic6dOxMdHU1eXh5Tp05l586dAHTu3Jmnn34agHfeeYdvv/0W\ns9nMHXfcwdChQwH7jloffvghf/75J48//jh33HEHq1evZsGCBfj4+GAYBq+++mqxa7KLVAUKb5EK\n8OCDDzJw4EDuvvtumjdvXqrv/Prrr7zxxhvUrFmTjh070rFjRxYtWkR0dDRff/01DzzwAGDf6nbM\nmDEsW7aMt99+m7feeovnnnuOuXPn0rhxY/bs2UNMTAyxsbGAfV38xYsXF7hWZmYmEydOZPny5dSv\nX5/Fixcze/ZsXn31VeLi4rjuuusuuoe9d+9eli1bhs1mY8CAAdx5553s27ePw4cPs2TJEmw2G1FR\nUdxwww2YzWbi4uL49NNPsdlsPPHEE9x+++2AfXOH9957j82bN/Piiy9yxx13MG/ePF5++WXatm3L\ntm3bOHHihMJbqjSFt0gF8PLyYty4cUyZMsWx5rYzoaGhjvXfa9euTbt27QD7phvn70nftWtXANq3\nb8/ChQtJSUlh//79/OMf/3B8JiMjA5vN5vjchf7880/q1Knj6M136tSJTz75xGkb58+fX+B+fmho\nKJMnTwbsvWoPD/s/Oa1btyYhIYFt27bRpUsXTCYTFouFDh06sH37dgCuu+46LBaLY9QhX6dOnQCo\nX78+p0+fBuCuu+4iOjqaPn360KdPH9q2beu0rSLuTOEtUkG6d+/OkiVL+OabbxzHTCZTgc/k5uY6\nfn3+kPaFr89f5dhsNjuOmUwmx2YPixYtKrIdRa1/fWE78s/lTEn3vPN/WDj/fCVdp7iVm/N/ADj/\nMw888AC33norP/zwAy+88AKDBg0iKirKaXtF3JVmm4tUoJiYGGbNmkVOTg4Afn5+HD9+HICUlBT2\n7t170eeMj48H7NsTtmjRAn9/fxo2bMjatWsB2L9/P2+//XaJ52jatCkpKSkcPXrUcc7L7c1u2rSJ\nvLw8cnJy2L59Oy1btuTaa6/lp59+wjAMrFYrGzdupG3btrRr1474+Hhyc3OxWq0MGzaMxMTEIs+b\nl5fHzJkz8ff3Z+DAgTzxxBOOnZ1Eqir1vEUqUOPGjenbt69jWLhr164sWLCAwYMHExoa6hgaLy2L\nxcLevXv55JNPSEtL47XXXgNg+vTpvPLKK7z33ntYrVaio6NLPE+NGjWYMmUKzzzzjGMf7ylTpji9\n/oXD5gBPPPEEAI0aNeKpp57i8OHDDBgwgNDQUJo1a8bWrVu59957sdls9O7dm+uuuw6APn36MGTI\nEAAGDBhQ7D7IFouFgIAAoqKiqFWrFgATJ0502lYRd6ZdxUTE5ebMmYPVauWZZ56p6KaIVAkaNhcR\nEXEz6nmLiIi4GfW8RURE3IzCW0RExM0ovEVERNyMwltERMTNKLxFRETcjMJbRETEzfw/NlS4/8C6\nRqcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f62ea8b0d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEII4WX+H1dywFlVSnzUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}